{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40dbf50e",
   "metadata": {
    "id": "40dbf50e"
   },
   "source": [
    "# 9. ГЛУБОКОЕ ОБУЧЕНИЕ ДЛЯ ВРЕМЕННЫХ РЯДОВ\n",
    "Глубокое обучение для временных рядов — это относительно новое, но очень перспективное начинание. Будучи необычайно гибким методом, глубокое обучение как нельзя лучше подходит для анализа временных рядов. Наиболее многообещающая его особенность заключается в способности моделирования сложного и нелинейного временного поведения без построения предположений о его функциональных проявлениях. Такой подход в корне изменяет ситуацию в отрасли нестатистических методов прогнозирования.\n",
    "\n",
    "Для тех, кто не знаком с глубоким обучением, приведем его краткое описание, длиной в один абзац (конечно же, далее оно рассматривается более подробно). Глубокое обучение — это отрасль машинного обучения, основанная на анализе графа, соединяющего входные узлы со сложной структурой узлов и ребер. При переходе от одного узла к другому по ребру значение умножается на вес этого ребра, а затем, как правило, подвергается нелинейной активации с помощью специальной функции. Именно эта нелинейная функция активации делает глубокое обучение настолько интересным: она позволяет описывать очень сложные, нелинейные данные, что не удавалось сделать традиционными методами.\n",
    "\n",
    "За последние 10 лет глубокое обучение достигло максимального развития благодаря широкой доступности и повышению производительности вычислительных устройств, а также наличию огромных объемов данных, необходимых для обучения сложных моделей. Модели глубокого обучения могут иметь миллионы параметров. Чтобы понять, как они устроены, представьте себе произвольный граф, расчет которого выполняется по всем возможным методикам умножения матриц и нелинейных преобразований, связанный с интеллектуальным механизмом оптимизации модели одномоментно по одному небольшому набору данных, веса которого пошагово корректируются таким образом, чтобы каждый раз выдавать все более и более точные результаты. Так работает глубокое обучение в двух словах.\n",
    "\n",
    "В отличие от других предметных областей, таких как обработка изображений и анализ текстов, в прогнозировании глубокое обучение не демонстрирует поражающие воображение результаты. Тем не менее есть все основания полагать, что в конечном счете с его участием прогнозирование выйдет на качественно новый уровень, обеспечив сокращение набора весьма однородных допущений и технических требований, свойственных традиционным моделям прогнозирования.\n",
    "\n",
    "При использовании глубокого обучения нивелируются многие проблемы, связанные с предварительной обработкой данных.\n",
    "\n",
    "- Отсутствует требование стационарности данных.\n",
    "\n",
    "- Нет необходимости в развитии навыков (искусства) выбора параметров, таких как оценка сезонности и порядка модели ARIMA.\n",
    "\n",
    "- Не нужно разрабатывать гипотезу о базовой динамике системы, без которой не обойтись модели пространства состояний.\n",
    "\n",
    "Эти преимущества покажутся вам знакомыми в свете материала разделе 8, в котором многие из них обсуждались в контексте применения машинного обучения к временным рядам. По ряду причин глубокое обучение является еще более гибким средством.\n",
    "\n",
    "- Многие алгоритмы машинного обучения являются ограниченными с точки зрения размерности и типов входных данных. Напротив, глубокое обучение является очень гибким в отношении выбора модели и природы входных данных.\n",
    "\n",
    "- Неоднородные данные могут вызывать трудности в обработке с помощью многих широко применяемых методов машинного обучения, тогда как в моделях глубокого обучения они используются довольно часто.\n",
    "\n",
    "- Модели машинного обучения редко создаются для анализа временных рядов, тогда как глубокое обучение предлагает большую гибкость при разработке архитектур, специально предназначенных для обработки временных данных.\n",
    "\n",
    "Тем не менее глубокое обучение не является панацей в анализе временных наборов данных. Хотя в глубоком обучении, применяемом к временным рядам, требование стационарности не выдвигается, на практике глубокое обучение не позволяет хорошо согласовать данные с трендом, если стандартные архитектуры не модифицированы под этот тренд. Следовательно, все еще нужно предварительно обрабатывать исходные данные или подвергать модификации сам метод.\n",
    "\n",
    "Кроме того, глубокое обучение лучше всего работает с числовыми входными данными, поступающими из разных каналов, которые масштабируются до одинаковых значений в диапазоне от -1 до 1. Это еще одно требование в пользу предварительной обработки данных, хотя в строго теоретическом изложении метода ее выполнять не обязательно. Более того, входные данные необходимо предварительно обработать таким образом, чтобы избежать упреждения, но сообщество глубокого обучения в целом обращает на эту проблему не слишком много внимания.\n",
    "\n",
    "Наконец, методы оптимизации глубокого обучения и моделирования для ориентированных на обработку временных данных нейронных сетей (самый большой класс из которых — рекуррентные нейронные сети (Recurrent Neural Networks — RNN)) не так хорошо развиты, как равнозначные инструменты обработки изображений (самый большой класс среди которых — сверточные нейронные сети, или (Convolutional Neural Networks — CNN)). Это означает, что вы найдете значительно меньше информации по методам оптимизации и практическим правилам выбора и обучения архитектур, предназначенных для решения задач обработки временных данных, в отличие от таковых, основанных на работе с “не временными” данными.\n",
    "\n",
    "Помимо этих трудностей применения глубокого обучения к временным рядам, существуют и другие проблемы. Для начала отметим, что эффективность глубокого обучения для временных рядов не всегда превосходит традиционные методы прогнозирования и классификации временных рядов. Действительно, прогнозирование — это предметная область и дисциплина, дальнейшее развитие которой неотрывно связано с технологиями глубокого обучения, хотя на момент написания статьи серьезных достижений в этом направлении пока не наблюдалось.\n",
    "\n",
    "Тем не менее от использования алгоритмов глубокого обучения в анализе временных рядов стоит ожидать серьезных достижений как в близкой, так и долгосрочной перспективе.\n",
    "\n",
    "Во-первых, крупные технологические компании начали применять глубокое обучение для анализа временных рядов в своих службах с собственной архитектурой, которая зачастую разрабатывается с учетом отраслевых задач моделирования. Вы можете использовать такие службы в собственных целях или комбинировать их с другими методами анализа, чтобы добиться действительно хорошей производительности.\n",
    "\n",
    "Во-вторых, вполне возможно, что ваши наборы данных временных рядов в исходном виде хорошо подходят для обработки методами глубокого обучения.\n",
    "\n",
    "В целом, чем больше соотношение “сигнал/шум”, тем лучше проявляет себя глубокое обучение. На данный момент ко мне приходят сообщения от многих начинающих программистов о получении удивительно хороших результатов с помощью относительно простых инструментов глубокого обучения.\n",
    "\n",
    "Например, исследователи одного из колледжей обнаружили, что простой метод LSTM (см. далее) так же хорошо, как и перегруженные работой преподаватели, предсказывает, какие студенты могут потерпеть неудачу при сдаче экзаменов или даже бросить учебу, что позволяет руководству колледжа заранее связаться с такими студентами и предоставить специальные условия обучения.\n",
    "\n",
    "Несмотря на то, что лучшим решением все же признается увеличение количества преподавателей-кураторов, отрадно понимать, что даже простой метод LSTM, применяемый к разнородным временным рядам, включающим одни только оценки учащихся и показатели посещаемости, способен выявить слабых студентов, указывая на необходимость дополнительной их поддержки. В будущем от такого инновационного способа применения глубокого обучения для анализа временных рядов стоит ожидать намного более серьезных результатов.\n",
    "\n",
    "Помните, что каждая модель основана на своих предположениях. Модели машинного обучения, включая нейронные сети, неизменно имеют встроенные допущения как в архитектуре, так и в методах обучения. Уже тот факт, что большинство нейронных сетей лучше всего работают с входными данными, масштабированными на отрезке [-1,1], говорит о том, что в модель заложены сильные предположения, даже если они не сформулированы явным образом.\n",
    "\n",
    "Возможно, область прогнозирования методами нейронных сетей еще не достигла своего предела в развитии, и более глубокое понимание их теоретических основ и требований позволит добиться существенного прироста в точности.\n",
    "\n",
    "Если вы только начинаете изучать технологии глубокого обучения, то примите к сведению, что этот раздел не даст вам полного представления обо всех концепциях и программном обеспечении, необходимом для успешного начала их освоения.\n",
    "\n",
    "Тем не менее она послужит хорошей отправной точкой на этом пути. Существует множество хороших учебных пособий, руководств и даже онлайн-курсов, которые вы можете использовать для овладения методами глубокого обучения.\n",
    "\n",
    "Хорошая новость о методах глубокого обучения состоит в том, что вам не обязательно хорошо знать математику, чтобы получить общее представление о принципах их работы и реализации в программном коде. Кроме того, вам доступны многочисленные специализированные интерфейсы прикладного программирования (API), представляющие механизмы глубокого обучения. Это означает, что начинающие исследователи могут использовать такие высокоуровневые API для опробования базовых методов, и по большому счету они часто применяются даже опытными специалистами в целях экономии рабочего времени и усилий.\n",
    "\n",
    "Впоследствии, по мере возникновения необходимости в конкретных архитектурных изменениях и представлении о преимуществах низкоуровневых API, которым приходится уделять намного больше внимания, вы все больше будете склоняться к использованию именно их.\n",
    "\n",
    "В этом разделе представлен краткий обзор математических концепций, лежащих в основе глубокого обучения, а также приведены примеры кода, который вы можете использовать в собственных целях — для обработки временных данных с помощью известных алгоритмов глубокого обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6729846",
   "metadata": {
    "id": "e6729846"
   },
   "source": [
    "## Концепции глубокого обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9d977-2443-4892-a5a0-aa3f6ccf2d35",
   "metadata": {},
   "source": [
    "Глубокое обучение имеет связь со многими предметными областями. В его возникновении есть определенные биологические предпосылки, поскольку разработчики — преимущественно специалисты по компьютерным наукам и вычислительной математике — постоянно задавались вопросом, смогут ли интеллектуальные устройства имитировать работу человеческого мозга, обеспечивая активацию сети нейронов в ответ на срабатывание определенных триггеров. У глубокого обучения также есть математическое обоснование, представленное теоремой об универсальной аппроксимации, которая была доказана для различных функций активации, причем многие из доказательств были выполнены в конце 1980-х и начале 1990-х годов. Наконец, быстрый рост производительности вычислительного оборудования, его повсеместная доступность и постоянно возрастающий интерес к машинному обучению стали причиной успехов, доказавших, что при достаточном количестве данных и параметров моделированию и прогнозированию подлежат очень сложные системы. Глубокое обучение еще больше расширило идею нейронной сети, позволив создать структуры, описываемые миллионами параметров и обучаемые на больших наборах данных. Они предоставили теоретическое обоснование возможности представления с помощью нейронной сети произвольной нелинейной функции с достаточной точностью. На рис. 9.1 показана простейшая нейронная сеть — многослойный персептрон (или полносвязная сеть).\n",
    "\n",
    "![data](picture1.png)\n",
    "\n",
    "*Рис. 9.1. Простая сеть прямого распространения*\n",
    "\n",
    "На рис. 9.1 показано, что многоканальные входы представлены в модели в виде вектора размерности d. Узлы задают входные значения, а ребра — соответствующие весовые множители. Значение каждого ребра, входящего в узел, рассчитывается через предыдущее значение, умноженное на весовой коэффициент этого ребра. Впоследствии значения ребер, поступающих в узел со всех входов, суммируются, а затем, как правило, передаются в функцию активации, устанавливающую степень нелинейности системы.\n",
    "\n",
    "Как видите, вход включает три канала, описываемых вектором с длиной, равной 3. В сети также присутствуют четыре скрытых элемента. Следовательно, каждый из трех входов нужно умножить на различные весовые коэффициенты каждого из четырех скрытых элементов, к которым он направлен. Это означает, что нам потребуется 3 • 4 = 12 весовых коэффициентов, чтобы полностью описать систему. Кроме того, поскольку полученные произведения подлежат итоговому суммированию, все необходимые вычисления проще всего проводить в матричном виде.\n",
    "\n",
    "При пошаговом описании алгоритм выглядел бы примерно следующим образом.\n",
    "\n",
    "1. Входной вектор X включает три элемента. Веса первого слоя обозначены W1 и образуют матрицу размером 4 x 3, так что для получения значений скрытого слоя необходимо вычислить произведение W1 X1 . Его результатом будет матрица размером 4 х 1, но она не будет представлять выход скрытого слоя (W1X1).\n",
    "2. Нужно добавить в систему нелинейность, которая имитируется с помощью самых разных функций активации, таких как гиперболический тангенс (tanh) или сигмоидальная функция. Обычно в самой функции активации также задается смещение В1 поэтому полный выход скрытого слоя рассчитывается следующим образом:\n",
    "Н = a (W1X1 + В1)\n",
    "3. Нейронная сеть, изображенная на рис. 9.1, имеет два выхода для предсказания. Следовательно, нужно привести четырехмерный выход скрытого состояния к двум выходам конечного состояния. Как правило, последний слой не снабжается нелинейной функцией активации, за исключением использования для решения задачи классификации многомерной логистической функции. Давайте полагать, что нам нужно предсказать два числа, а не вероятностные категории, что позволяет “уплотнить” последний слой — объединить четыре выхода скрытого слоя в единый результат. В нашем случае последний плотный слой представлен двумя выходами, сведенными из четырех, для чего применяется матрица W2 размером 2x4 (Y = W2X).\n",
    "\n",
    "Надеюсь, приведенное выше описание дало вам хотя бы общее представление о работе моделей глубокого обучения. Общая идея состоит в том, чтобы иметь множество параметров и возможностей для описания нелинейных систем.\n",
    "\n",
    "Выбор правильного числа и конфигурации параметров, правильные обучающие гиперпараметры и, конечно, разумно поставленная задача больше сродни искусству, чем науке. Секрет заключается в том, чтобы научиться настраивать параметры модели, выработать правильный подход к их инициализации и убедиться в движении модели в правильном направлении — к приемлемому решению.\n",
    "\n",
    "Это невыпуклый класс моделей, цель применения которых не сводится к нахождению глобального оптимума. Вместо этого поиск продолжается до тех пор, пока не будет найден хорошо продуманный способ упорядочения модели, представленный “достаточно правдоподобным” локальным оптимумом, который полностью соответствовал бы вашим потребностям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e9b6f-5cd8-4072-b940-f44fa4cdf832",
   "metadata": {},
   "source": [
    "## Программирование нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb2a52-e3f0-4523-b747-b397c6c679bd",
   "metadata": {},
   "source": [
    "Понимание принципов работы нейронных сетей может оказаться несколько более простой задачей, чем изучение фреймворков и программных инструментов, применяемых для их реализации. Как вы увидите далее, несмотря на широкое разнообразие все они имеют много общего."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bad3ff-c297-49d7-9f67-10f61ae1eac9",
   "metadata": {},
   "source": [
    "## Символическое и императивное программирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0b08f-81fc-4a2c-b04b-bcc0955fe605",
   "metadata": {},
   "source": [
    "При программировании глубокого обучения перед вами встанет задача выбора стиля программирования: символического или императивного. В символическом программировании все отношения объявляются заранее, не подвергаясь вычислению во время объявления. Напротив, в императивном программировании вычисления выполняются по мере прохода по коду — построчно, не дожидаясь объяснения того, что произойдет позже. У каждого стиля есть свои достоинства и преимущества, и между ними нет строгого разделения. Перечислим некоторые особенности стилей программирования, о которых нужно помнить, выбирая один из вариантов:\n",
    "- Код символического стиля программирования, как правило, более производительный, поскольку лишен строгого порядка выполнения и сохраняет возможность оптимизации за фреймворком.\n",
    "- Код императивного стиля программирования проще для понимания и отладки.\n",
    "- Фреймворки TensorFlow и MXnet тяготеют к символическому стилю программирования, в то время как фреймворк Torch носит более императивный характер.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d33d3-7ab9-4660-967b-5ef1df8260d9",
   "metadata": {},
   "source": [
    "## Данные, символы, операции, слои и графы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07ca10-b2d3-469d-b534-5d5c3f1a5535",
   "metadata": {},
   "source": [
    "Работа фреймворков глубокого обучения часто концентрируется вокруг некого представления графа и методов его построения. Идея состоит в том, чтобы описать предложенную структуру по отдельным ее компонентам и взаимоотношениям между ними. Кроме того, в них преобладает идея отрыва переменных от их фактических значений. Остановившись на ней, представим, что модель оперирует понятиями символов А и В, а также третьего символа С, представляемого через произведение матриц А и В.\n",
    "\n",
    "#Псевдо-код\n",
    "\n",
    "symbol А;\n",
    "\n",
    "symbol В;\n",
    "\n",
    "symbol С = matmul(А, В);\n",
    "\n",
    "Различие между символами и данными играет важную роль в каждой структуре из-за связи между символом и данными. Символ используется для изучения общих взаимоотношений, а данные могут иметь шум. Существует только один символ А, хотя у нас могут быть миллионы или даже миллиарды значений, которые может принимать переменная А в паре с соответствующими переменными В и С."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722f9e0-d978-46e9-af3e-e151a8dc4726",
   "metadata": {},
   "source": [
    "## Популярные фреймворки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8eb6a1-2b86-4f59-98d6-9e788fa4c645",
   "metadata": {},
   "source": [
    "Как и во многих других высокотехнологических отраслях, карта предложений в мире глубокого обучения постоянно меняется. И так же, как в деловом мире, здесь часто происходят непродуманные слияния и поглощения, как, например, в случае совмещения TensorFlow и Theano, а также MXNet и Caffe. Ни один из фреймворков не зарекомендовал себя в качестве лидера на рынке технологий глубокого обучения для временных рядов, хотя MXNet может оказаться лучшим выбором в ближайшем будущем, учитывая высокую заинтересованность компании Amazon в инструментах прогнозирования, подобных недавно представленной службе глубокого обучения для анализа временных рядов. Как человек, которому часто приходится писать собственные итераторы данных для проектов  по анализу временных рядов с помощью методов глубокого обучения, я обнаружила, что проще всего выполнять эту задачу в MXNet.\n",
    "\n",
    "На момент написания пособия наиболее известными и широко используемыми для начинающих специалистов считались следующие библиотеки (в скобках указан разработчик).\n",
    "\n",
    "- TensorFlow (Google)\n",
    "\n",
    "- MXNet (Amazon)\n",
    "\n",
    "- Torch (Facebook)\n",
    "\n",
    "Тем не менее в академических и открытых источниках часто предлагаются совершенно другие, более новые решения, оптимизированные для задач отдельной предметной области или как минимум улучшающие существующую структуру. Доминирование на рынке рано и поздно заканчивается, хотя в силу выпуска технологическими гигантами оборудования, работающего исключительно с программным обеспечением их собственной разработки, лидеры рынка, скорее всего, будут удерживать свои позиции несколько дольше, чем в предыдущие годы.\n",
    "\n",
    "Если спросить о том, зачем нужны данные, то можно получить ответ: «Чтобы совершать над ними определенные операции, например, добавлять или умножать символы, представляя эти действия как операции. Кроме того, с ними можно совершать одномерные операции, такие как изменение формы символа (в частности, приведение изображения символа А из матрицы 2 х 4 к матрице 8x1) или передача значений функции активации, такой как tanh(A).\n",
    "\n",
    "Поразмыслив еще, слои можно представить в виде элементов общих структур, обрабатываемых с помощью стандартных методик, например, полносвязных слоев, описанных в предыдущем разделе. Принимая во внимание функцию активации и смещение, а также структуру матрицы ядра, можно сформулировать следующее утверждение:\n",
    "Слой L = tanh(AB + смещение)\n",
    "\n",
    "Во многих фреймворках такой слой выражается не с помощью нескольких операций, а через один или два слоя, в зависимости от того, достаточно ли репрезентативна комбинация операций, чтобы представить отдельный слой.\n",
    "\n",
    "Наконец, несколько слоев можно связать между собой, подставив один в другой:\n",
    "\n",
    "Слой L1 = tanh(AB + смещение_1)\n",
    "\n",
    "Слой L2 = tanh(L1D + смещение_2)\n",
    "\n",
    "Такой конгломерат символов, операций и слоев представляет собой граф. Граф не обязательно должен быть полностью связанным, т.е. не обязательно, чтобы все символы зависели друг от друга. Граф используется для того, чтобы разобраться, как символы зависят от других символов и от каких именно. Это важно для понимания того, как лучше настраивать веса в каждой итерации для получения лучшего решения при вычислении градиентов в методе градиентного спуска.\n",
    "\n",
    "Приятно то, что большинство современных пакетов глубокого обучения полностью автоматизируют большую часть работы. Нам не нужно указывать, что от чего зависит и как меняется градиент с каждым добавленным слоем, - все это делается фреймворком самостоятельно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa099cc7",
   "metadata": {
    "id": "fa099cc7"
   },
   "source": [
    "## Демонстрация работы с помощью фреймворка MXnet\n",
    "Более того, как указывалось ранее, всегда можно обратиться к высокоуровневым программным интерфейсам, в которых не нужно заниматься перемножением матриц, как показано в предыдущем примере. Для работы с полносвязными слоями, описываемыми с помощью уже известной вам процедуры суммирования произведений матриц с последующей поэлементной обработкой в функции активации, можно отказаться от выписывания всех необходимых математических выражений. Например, в пакете MXNet эта сложная задача реализуется с помощью следующего простого кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad82ddb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ad82ddb",
    "outputId": "b0572134-daf8-4f8c-a16a-e4e3f74cb764"
   },
   "outputs": [],
   "source": [
    "# pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5c3d13",
   "metadata": {
    "id": "4f5c3d13"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jVon9_IMnCNg",
   "metadata": {
    "id": "jVon9_IMnCNg"
   },
   "outputs": [],
   "source": [
    "fcl = mx.gluon.nn.Dense(120, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "GoOK84NXnI-2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoOK84NXnI-2",
    "outputId": "ca46c4e4-938e-41ed-905e-5b0157eaadd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(None -> 120, Activation(relu))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ZruDzynOZ9",
   "metadata": {
    "id": "25ZruDzynOZ9"
   },
   "source": [
    "Результатом его выполнения будет полносвязный слой, который преобразует входные данные в выходное измерение размером 120. Кроме того, в единственной строке кода полностью реализуются все необходимые расчеты: перемножение матриц, последующее их суммирование и поэлементный проход функцией активации.\n",
    "\n",
    "Вы можете удостовериться в этом, сверившись с документацией к пакету (https: //perma.cc/8PQW-4NKY) или протестировав его на примерах входных и выходных данных, для которых известны весовые коэффициенты. Удивительно, но программный интерфейс выполняет задачу полностью автоматически. От вас не требуется указывать входную форму данных (хотя она должна быть постоянной после построения графа, чтобы иметь возможность получить конечный результат). Вы не обязаны определять тип данных — по умолчанию это будет наиболее предпочтительный и часто используемый float32 (тип float64 излишне громоздкий для глубокого обучения). Если исходные данные в одной из выборок представлены не в одномерной форме, то они будут автоматически сглажены для соответствующего слоя так, чтобы передаваться в полносвязный/плотный слой в должном формате. Автоматизированный программный интерфейс покажется хорошим решением для начинающих исследователей, но как только вы достигнете определенного уровня квалификации, обязательно пересмотрите документацию, чтобы досконально разобраться в выполняемых операциях — пусть даже в простейшей модели глубокого обучения.\n",
    "\n",
    "В приведенном далее примере у вас не запрашивается почти ничего из того, что приходится определять при выполнении даже самой простой задачи глубокого обучения. Здесь от вас требуется определить только входные данные, конечные цели и то, какие ошибки будут учитываться. Вам также нужно указать, как слой должен размещаться в модели, для чего применяется следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sOvzZaatnN84",
   "metadata": {
    "id": "sOvzZaatnN84"
   },
   "outputs": [],
   "source": [
    "## Создание сети, а не отдельного слоя\n",
    "from mxnet.gluon import nn, loss, Trainer\n",
    "from mxnet import init\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(120, activation='relu'), nn.Dense(1))\n",
    "net.initialize(init= init.Xavier())\n",
    "## Определение ошибок\n",
    "L2Loss = loss.L2Loss()\n",
    "trainer = Trainer(net.collect_params(), \"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CTgc5pk-r9MM",
   "metadata": {
    "id": "CTgc5pk-r9MM"
   },
   "source": [
    "Наконец, предполагая, что данные уже настроены так, как нужно, можно переходить непосредственно к этапу обучения (совершить один проход по всем данным), как показано далее.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qaF_qgTXr__3",
   "metadata": {
    "id": "qaF_qgTXr__3"
   },
   "outputs": [],
   "source": [
    "def get_data(train_data):\n",
    "    for data, target in train_data:\n",
    "    ## Вычисление градиента\n",
    "      with autograd.record() :\n",
    "        out = net (data)\n",
    "        loss = L2Loss(output, data)\n",
    "        loss .backward ()\n",
    "        ## Применение градиента для обновления параметров\n",
    "    trainer.step(batch_size)\n",
    "    net.save_parameters('model.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98402b-1baa-42b9-bc24-762decc0bf68",
   "metadata": {},
   "source": [
    "В последующих примерах мы будем использовать программный интерфейс Module пакета mxnet, чтобы продемонстрировать другие способы создания графов и обучающих моделей.\n",
    "\n",
    "Как специалист по глубокому обучению вы в конечном итоге придете к знакомству со всеми основными пакетами и их наиболее популярными программными интерфейсами (как правило, каждый пакет имеет не менее одного высокоуровневого и одного низкоуровневого API), что позволит вам легко изучать любые примеры кодов. Знание основных пакетов глубокого обучения понадобится вам, чтобы не отставать от развития отраслевых технологий и быть в курсе тематических академических исследований, а эту информацию проще всего почерпнуть из открытых источников кода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cOGhC4x5suXE",
   "metadata": {
    "id": "cOGhC4x5suXE"
   },
   "source": [
    "## Автоматическое дифференцирование\n",
    "Магия моделей глубокого обучения — помимо впечатляющей производительности — заключается в способности обучения чему угодно. Стандартные модели могут иметь тысячи или даже миллионы параметров, и эти параметры должны быть адаптированы к конкретной задаче. Как правило, это предполагает задействование сложных механизмов символического дифференцирования, которые предоставляются специальными фреймворками глубокого обучения. В последние десятилетия большинство математиков, физиков и исследователей других дисциплин, сталкивающихся с необходимостью оптимизации функций, полагались на методы численной оптимизации и дифференцирования, а это означает, что градиент определялся ими эмпирически (скажем, с помощью зависимости вида ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMEAAAAjCAYAAAAtzm4VAAAAAXNSR0ICQMB9xQAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABl0RVh0U29mdHdhcmUATWljcm9zb2Z0IE9mZmljZX/tNXEAAASWSURBVHja7Vy9UuMwENYD8AAwE6XjAYJIeVc6HoYHIPFQHUPF6IbhARy6zNzwAunojie4hvYa3oCCN+Ad7pCNTH5sa3dlKxKo2IIkWNpv99tdrddmt7e3LEqUrywRhCiRBBGEKJEELV/mMh2lmTyJQEWhiszSk1TmoyBJoAggRJZHQ0axkcXicm8m+J3PRKgnQH5+IIaT5eVisRcNGcVWlD8d8+Pf53l+EAwJFHNFNj91li4DLrlCSPd94g/V/yrhN0zM7oMggSqDODt6orJWgXLE2RNj7B8Xs7vW3ybiQiTyIvi6902PcSbPfHFq1/hD9FfZ4IjxJ2rAmGfi1KRPZySYCXZPZWzBdsZfVWQpycSfm5TuU6lunWp8xjl7Vk5VCn/ddBxV96acP7jKnr7hD9Wf6lv6+hgCQexWS4LiLMDYC0+ubihMLaLP+/+Wf4uXuoxiGxVciSoLVyNc6WQloJt7t82gtrJr/CH6l/jV76nLLICx2xYJNJDYiFYwdcAeoQoWmxqkjz4fvIuAsNEdq/Ss2bv+jhJAOonEO8Yfoj/Fv7BZAGu3LRJU6RQRIdQCWcrz1Shk3CQx21BLBMpaZUeD/8HU+tRIZ+t8vuBv0r/MFuwVszY2C1DsRo4mVY1X1VzvYqj5oNFAyuloIobL1etpEDF1JZUEa0Z7MwIkalIzKb1c8wt/07U1AaFZiNpaxdpte4PISGZKNfWGa882FdgrddzaZ45IsL4Xc4akkLSzUsgD/E36Y32siwAGsRuZpRTDY7ONOuHrNJ8K8Wsq80MX5VBZYoyvh2KynEo5UlGxNJ7BeYgY2h9I/cDfpD+GBJQsQLXbNphIA2JKAGwk+DDamxLT/LuLM4HCYTAY/N0ETevZ5mzUbNpFV8gH/E3XX7ueITq7tJs1CSDp1WaN8vqIrsdmjdwgdU7TdmiERHmTkTH7gzqAT/ib9IeSAJsFbO1mBRC2HqWsQelYUSNKm8EhnQ1MpNvFeaBv/LsigVoT01ywtZtVKsceBLFGUHtKkuSnTUsPSoJK/wZdIM7gmgS+4Q8ngaGNytMHKEm7sJsVCXR6h7IWu0aWpj/kXO4XwL0rOZdyvxcStDiU/s6kp+szgW/4m64PWR87vNmF3Tq4TwD/PWQNPV+yOp1YrSPPv43T7LoPEqxGMX2jRX1WzKC0zODssjvkG/7g7lDT98gs0JXdyPUf9c6j6SBX3v38UEif8DE3P6hnglxOD/UEZiGcPyujg1Ozw/sEPuJvvE9gqM+pI/y2diO329oGtLpq6YUmLnXzEX/TtX21PTi6bA5dqYhCnclxOTvkUvqcHQoBf5P+u5itQpOgSpc1NZsGXQ9s2cyihzBFSm1X9kVu3/GH6G/zrIpTEjTNheu6sKgXEfVWUzQK4XkCXF3a7/MEvuNv0t9nm7dGnb5rWmwnwGdx+Vy2j/ib9Pf5ScLGSOHi7QCqjfVZnjEOUY+u8Dfpr0qlyVAsg3rbRJXeHETq0F/wFfrbMmzxh+ifCZEH996hz+KgUTwJEqG+gS5KlK8iEYQokQQRhCiRBBGEKJEEEYQoX1v+A+CL8QydmIdPAAAAAElFTkSuQmCC).\n",
    "Преимуществом такого подхода было отсутствие необходимости в обучении компьютеров дифференцированию, выполняемому в явном виде, а недостаток был всего один — низкая скорость вычислений, и повысить ее не позволял даже тот факт, что все необходимые математические зависимости давно известны или специально установлены.\n",
    "\n",
    "Автоматическое дифференцирование основано на фактической известности математических выражений, которые описывают взаимосвязь переменных, относящихся к разным слоям, а значение градиента рассчитывается согласно таким выражениям, а не более вычислительно затратным методам численного дифференцирования.\n",
    "\n",
    "В частности, в автоматическом дифференцировании используется тот факт, что в компьютерных алгоритмах, даже в большей степени, чем в математике, любые сложные математические выражения можно представить последовательностью более простых операций, правила дифференцирования которых заведомо известны, а потому к ним можно в полной мере применять правила дифференцирования сложных функций. В автоматическом дифференцировании такой подход применяется для нахождения математических выражений вычисления градиентов. Как только градиенты будут получены, можно переходить к установке весовых значений в разные моменты времени, тем самым улучшая и обучая модель.\n",
    "## Создание конвейера обучения\n",
    "В этом разделе мы займемся моделированием одного и того же набора данных, содержащего измерения почасового потребления электроэнергии в различных населенных пунктах за последние несколько лет. Данные будут подвергаться предварительной обработке так, чтобы предоставлять сведения о потреблении электроэнергии ежечасно, что является более сложной задачей, чем прогнозирование суммарных значений, поскольку требует анализа наиболее непредсказуемых диапазонов временного ряда.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NFly8pHyx3wj",
   "metadata": {
    "id": "NFly8pHyx3wj"
   },
   "source": [
    "## Исследование набора данных\n",
    "\n",
    "### --- в R файле\n",
    "................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W64LgctHyF8_",
   "metadata": {
    "id": "W64LgctHyF8_"
   },
   "source": [
    "## Этапы конвейера обучения\n",
    "Как правило, сценарии моделирования с помощью нейронной сети включают нескольких стандартных этапов. Зачастую такие сценарии намного сложнее в реализации, чем в случае статистических или традиционных моделей машинного обучения, поскольку их целевые наборы данных обычно имеют заметно больший размер. Кроме того, обучение глубоких моделей выполняется пакетным способом с использованием итераторов, а не массивов полных наборов данных.\n",
    "Конвейер данных включает следующие производственные этапы.\n",
    "- Создание легко настраиваемого кода путем импортирования в него списка заранее оговоренных значений для параметров обучения, принятых по умолчанию. Это очень важная операция при определении слишком большого количества значений.\n",
    "- Загрузка в память и предварительная обработка данных.\n",
    "- Приведение данных к требуемому формату.\n",
    "- Создание итераторов, соответствующих используемому модулю глубокого обучения.\n",
    "- Построение графа, в котором применяются итераторы, для понимания ожидаемой формы данных; предполагается полное построение модели.\n",
    "- Настройка параметров обучения, например, оптимизации, скорости и длительности обучения.\n",
    "- Создание системы учета как весов, так и результатов поэтапных вычислений.\n",
    "## Создание легко настраиваемого кода\n",
    "В следующем коде показано, как можно реализовать перечисленные выше задачи. Начнем с команд импорта стандартных программных пакетов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "E93XZoNgywbw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E93XZoNgywbw",
    "outputId": "7fe26a0a-af3e-4e33-aa14-b5f17aea363e"
   },
   "outputs": [],
   "source": [
    "# pip install perf-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "QZyA2yEXyOg7",
   "metadata": {
    "id": "QZyA2yEXyOg7"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "## Пакеты для получения данных\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "## Модуль глубокого обучения\n",
    "import mxnet as mx\n",
    "\n",
    "## Пакеты для обработки данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Вывод результатов\n",
    "import perfpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PZt0WpFny5F8",
   "metadata": {
    "id": "PZt0WpFny5F8"
   },
   "source": [
    "Далее нужно определиться с комбинацией задаваемых в коде переменных и настраиваемых параметров. В какой-то степени это вопрос опыта и личных предпочтений, выработанных при обучении. Не расстраивайтесь, если названия переменных покажутся вам бессмысленными, ведь многие из настраиваемых параметров применяются в компонентах нейронной сети, которые нам только предстоит обсудить. Главное - отметить настраиваемость таких параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jf-gjtLky4ZN",
   "metadata": {
    "id": "jf-gjtLky4ZN"
   },
   "outputs": [],
   "source": [
    "## some hyperparameters we won't tune via command line inputs\n",
    "DATA_SEGMENTS    = { 'tr': 0.6, 'va': 0.2, 'tst': 0.2}\n",
    "THRESHOLD_EPOCHS = 2\n",
    "COR_THRESHOLD    =  0.005\n",
    "\n",
    "## temporal slicing\n",
    "WIN              = 24 ##* 7\n",
    "H                = 3\n",
    "\n",
    "## model details\n",
    "MODEL            = 'rnn_model'\n",
    "SZ_FILT          = 8\n",
    "N_FILT           = 10\n",
    "RNN_UNITS        = 10\n",
    "SEASONAL_PERIOD  = 24\n",
    "\n",
    "## training details\n",
    "GPU              = 0\n",
    "BATCH_N          = 1024\n",
    "LR               = 0.0001\n",
    "DROP             = 0.2\n",
    "N_EPOCHS         = 30\n",
    "\n",
    "## data details\n",
    "DATA_FILE        = 'electricity.txt'\n",
    "SAVE_DIR         = \"resultsDir\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8-jY66gezdSV",
   "metadata": {
    "id": "8-jY66gezdSV"
   },
   "source": [
    "Критически важно располагать большим количеством настраиваемых параметров, поскольку обучение модели глубокого обучения всегда предполагает поиск гиперпараметров, способных улучшить ее относительно базового уровня. Обычно настраиваемые гиперпараметры влияют на все аспекты обучения, от подготовки данных (как далеко нужно назад заглянуть во времени) до спецификации модели (насколько она сложная и какой имеет вид) и сложности обучения (насколько долго оно ведется и с какой скоростью).\n",
    "\n",
    "В предыдущий код включены разные категории параметров. Во-первых, формирование данных зависит от процедуры получения необработанных данных - в нашем случае из CSV-файла, содержащего параллельные разности временных рядов потребления электроэнергии, взятые из 321 станций. Чтобы сформировать наши данные, нам понадобится два параметра. Переменная окна — насколько далеко моделям позволено смотреть в прошлое при составлении прогнозов. Переменная горизонта - насколько далеко в будущее делается прогноз. Обратите внимание, что обе переменные относятся не к точным временным значениям, таким как “5 минут”, а скорее к временным шагам, в соответствии с практикой, выработанной в предыдущих разделах. Как и другие статистические и машинные модели обучения, нейронные сети заботятся о вычислительном представлении и не видят разницы между 5 минутами и 5 миллиардами лет при просмотре данных.\n",
    "\n",
    "Предпоследний раздел, в котором задаются настройки обучения, обычно самый важный для оптимизации гиперпараметров, а потому наиболее часто подвергаемый правкам. С самого начала очень важно поэкспериментировать со скоростью обучения и убедиться, что выбрано удачное значение. Хорошее эмпирическое правило — начинать с 0,001, а затем переходить вверх и вниз с шагом в несколько порядков. Важно иметь не столько правильную скорость обучения, сколько правильный порядок величин.\n",
    "\n",
    "Параметризация моделей позволяет получить различные виды сетей (например, RNN или CNN) и задать их структурные особенности. В общем, пренебрегать настройкой гиперпараметров не стоит.\n",
    "В представленных ниже примерах будут использованы следующие гиперпараметры, переданные сценарию из командной строки.\n",
    "\n",
    "--drop=0.2 --win=96 --batch-n=128 --lr=0.001 --n-epochs=25\n",
    "\n",
    "--data-dir=/data/elec --save-dir=/archive/results\n",
    "\n",
    "--model=model_will_vary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NmYZlvyIzg5t",
   "metadata": {
    "id": "NmYZlvyIzg5t"
   },
   "source": [
    "## Подготовка входных данных\n",
    "Настроив параметры, нужно сообщить сценарию, где искать файл, насколько далеким должен быть прогноз и как далеко можно заглядывать в прошлое при изучении данных. Такие настройки будут важны даже на этапе предварительной обработки данных: считывании и придании правильной формы. Нам также необходимо образовать инфраструктуру обработки данными, потому что в обучении нейронных сетей используются разные методы стохастического градиентного спуска, а это значит, что оно выполняется на небольших пакетах данных за один проход, за который для обучения используются полностью все данные (хотя и не все одновременно).\n",
    "\n",
    "Далее нам предстоит обсудить высокоуровневый процесс предоставления данных для обучения с помощью итераторов и принципы низкоуровневого формирования данных, передаваемых таким итераторам.\n",
    "\n",
    "Формирование входных данных. В предыдущем разделе вы познакомились с построением итераторов на основе массивов NumPy и приняли такое их представление как должное. Далее мы обсудим принципы формирования данных, сначала — концептуально, а затем — в виде практического примера. Будем рассматривать два формата данных — NC и NTC.\n",
    "\n",
    "Начнем изучение форматов входных данных с рабочего примера, который не имеет ничего общего с данными, приведенными в коде. Представим данные некого многомерного временного ряда со столбцами А, В и С.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JzgTlwKfzsy4",
   "metadata": {
    "id": "JzgTlwKfzsy4"
   },
   "source": [
    "Такой способ описания многомерной информации называется форматом данных NC, где N - отдельные выборки, а С - канал. Мы будем использовать этот формат данных для обучения полностью связанной нейронной сети, и это первый вариант метода, в котором входные данные поступают в формате CSV и преобразуются в массивы NumPy правильной формы и размерности.\n",
    "\n",
    "Наряду с этим данные можно сформировать по-другому, ориентируясь на специально образованную ось времени. Обычно это делается путем представления данных в формате NTC, в котором N обозначает количество выборок, Т  время, а С  каналы. В этом случае выборкой считается каждая строка исходных данных, т.е. каждый срез во времени, для которого нужно сделать прогноз (и для которого представлены данные, позволяющие это сделать). Показатель времени устанавливает, насколько далеко назад во времени будет проводиться анализ.\n",
    "\n",
    "В данном примере он равен двум шагам (и обозначается параметром  win в сценарии для этого раздела).\n",
    "\n",
    "В формате NTC исходные данные, с которыми мы работали ранее, для прогнозирования горизонта t - 1 выглядели бы примерно так.\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bZlY5iz8jj",
   "metadata": {
    "id": "c3bZlY5iz8jj"
   },
   "source": [
    "Ни одно из приведенных выше NTC-представлений не точнее других, но все они обладают важной особенностью, которая выражается в явной направленности значений вдоль временной оси.\n",
    "\n",
    "Причина, по которой используются сразу оба формата входных данных, заключается в том, что каждый из них лучше подходит для своего типа модели.\n",
    "\n",
    "Формат NTC будет применяться для передачи данных в сверточные и рекуррентные нейронные сети, которые мы подробно обсудим несколько позже.\n",
    "## NTC или TNC\n",
    "Есть несколько особенностей, которые стоит отметить в только что описанном формате хранения данных NTC. Во-первых, он избыточный. Это ограничение можно обойти, если порядок данных не важен, используя формат TNC вместо NTC. В формате TNC можно задействовать свою “пакетную” ось для параллельного обхода различных частей данных. Так, например, в приведенной ниже последовательности чисел одновременно обучается три пакета.\n",
    "\n",
    "56 29 56 94 10 92 52 32 19 59 88 94 6 57 73 59 95 79 97 38 65 51 27\n",
    "18 77 39 4 19 60 38 73 51 65 4 96 96 6 12 62 59 21 49 65 37 64 69\n",
    "36 32 48 97 33 44 63 99 10 56 75 20 61 53 71 48 41 2 58 18 4 10 17\n",
    "66 64 53 24 36 23 33 38 1 17 59 11 36 43 61 96 55 21 45 44 53 26 55\n",
    "99 22 10 26 25 82 54 82\n",
    "\n",
    "Если подготовить их в формате NTC с одним каналом, то данные будут выглядеть так.\n",
    "\n",
    "Время А\n",
    "\n",
    "t \t56, 29, 56, 94\n",
    "\n",
    "t-1 \t29,56,94,10\n",
    "\n",
    "t-2\t 56,94,10,92\n",
    "\n",
    "Здесь много повторений, но хорошая новость заключается в том, что алгоритм будет обучаться в реальном хронологическом порядке следования данных, так как все пакеты тесно связаны во времени. Напротив, если выбрать формат TNC (N — это число выборок на пакет) и предположить, что размер пакета равен 4 (меньше некуда), то наши данные могут выглядеть следующим образом.\n",
    "\n",
    "Время Элемент пакета 1 Элемент пакета 2 Элемент пакета 3 Элемент пакета 4\n",
    "\n",
    "t \t\t29 \t\t77 \t\t\t32 \t\t\t64\n",
    "\n",
    "t+1 \t\t56 \t\t39 \t\t\t48 \t\t\t53\n",
    "\n",
    "t+2 \t\t94 \t\t4 \t\t\t97 \t\t\t24\n",
    "\n",
    "Очевидно, что в данном случае повторений данных нет. Нужно ли проводить обучение на данных, упорядоченных в хронологическом порядке, зависит от набора данных. Те из вас, кому доводилось использовать методы глубокого обучения для обработки текстов на естественных языках (NLP), посчитают этот формат удобным для многих задач NLP, но он не всегда будет столь же эффективен в задачах анализа числовых значений временных рядов.\n",
    "\n",
    "Построение итераторов. В целом, чтобы передать данные в процедуру обучения, понадобятся итераторы. Итераторы не являются чем-то уникальным для глубокого обучения или языка Python, а скорее отражают общую идею объекта, который обходит коллекцию, отслеживая свое положение и сообщая, когда проход по коллекции будет закончен. Построить итератор в случае обучения на данных, передаваемых в виде массива NumPy, не составляет большого труда.\n",
    "\n",
    "Если X и Y выступают массивами NumPy, то получить итераторы очень просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BmthlCGK0Fh4",
   "metadata": {
    "id": "BmthlCGK0Fh4"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## ПОДГОТОВКА ДАННЫХ ##\n",
    "############################\n",
    "\n",
    "def prepare_iters(data_file, win, h, model, batch_n):\n",
    "    X, Y = prepared_data(data_file, win, h, model)\n",
    "\n",
    "    n_tr = int(Y.shape[0] * DATA_SEGMENTS['tr'])\n",
    "    n_va = int(Y.shape[0] * DATA_SEGMENTS['va'])\n",
    "\n",
    "    X_tr, X_valid, X_test = X[                      : n_tr], \\\n",
    "                               X[n_tr             : n_tr + n_va], \\\n",
    "                               X[n_tr + n_va : ]\n",
    "    Y_tr, Y_valid, Y_test = Y[                      : n_tr], \\\n",
    "                               Y[n_tr             : n_tr + n_va], \\\n",
    "                               Y[n_tr + n_va : ]\n",
    "\n",
    "    iter_tr = mx.io.NDArrayIter(data       = X_tr,\n",
    "                                   label      = Y_tr,\n",
    "                                   batch_size = batch_n)\n",
    "    iter_val = mx.io.NDArrayIter(  data       = X_valid,\n",
    "                                   label      = Y_valid,\n",
    "                                   batch_size = batch_n)\n",
    "    iter_test = mx.io.NDArrayIter( data       = X_test,\n",
    "                                   label      = Y_test,\n",
    "                                   batch_size = batch_n)\n",
    "\n",
    "    return (iter_tr, iter_val, iter_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2Hgu_H3Uz4Qq",
   "metadata": {
    "id": "2Hgu_H3Uz4Qq"
   },
   "source": [
    "В этом коде итераторы для набора данных создаются специальным методом, после чего они проходят по массивам NumPy, полученным с помощью метода prepare_data() (подробнее об этом - далее). Как только массивы с данными становятся доступными, они разбиваются на источники для обучения, проверки и тестирования, причем данные обучения создаются первыми, данные проверки используется для настройки гиперпараметров с обратной связью вне выборки, а данные тестирования сохраняются для полноценного тестирования (Как обсуждалось ранее, золотой стандарт заключается в обучении и продвижении моделей вперед через большое количество временных периодов, но мы будем избегать такого усложнения в нашем коде. В реальных задачах приходится постоянно проверять и тестировать полученные результаты для правильной оптимизации модели и получения полного представления о ее действительной производительности. В приведенной здесь методике вводится дополнительное смещение между данными тестирования и обучения, а это означает, что данные тестирования, используемые для оценки модели, на самом деле отражают всего один период времени из всего временного диапазона).\n",
    "\n",
    "Обратите внимание, что функция инициализации итератора принимает входные данные (data), целевое значение (label) и параметр batch_size, отражающий количество экземпляров, которые будут использоваться в итерации для вычисления градиентов и обновления весов модели.\n",
    "## Формирование данных в коде\n",
    "Познакомившись с двумя форматами данных, которые будут обрабатываться в коде, рассмотрим код подготовки данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nreKw35OzZL5",
   "metadata": {
    "id": "nreKw35OzZL5"
   },
   "outputs": [],
   "source": [
    "def prepared_data(data_file, win, h, model_name):\n",
    "    df = pd.read_csv(data_file, sep=',', header=0)\n",
    "    x  = df.iloc[:, :].values\n",
    "    ## Нормализация данных. Она вызывает упреждение, поскольку\n",
    "    ## основана на значениях, измеренных по всему набору.\n",
    "    ## Чтобы предотвратить упреждение, в реальных приложениях\n",
    "    ## следует применять скользящие статистики\n",
    "    x = (x - np.mean(x, axis = 0)) / (np.std(x, axis = 0))\n",
    "\n",
    "    if model_name == 'fc_model':  ## формат данных NC\n",
    "        ## Возврат на один и два шага назад во входных данных\n",
    "        X = np.hstack([x[1:-h], x[0:-(h+1)]])\n",
    "        Y = x[(h+1):]\n",
    "        return (X, Y)\n",
    "    else: ## Формат данных TNC\n",
    "        # Предварительное размещение X и Y в памяти\n",
    "        # X = количество экземпляров * временное окно *\n",
    "        # * количество каналов (NTC)\n",
    "        X = np.zeros((x.shape[0] - win - h, win, x.shape[1]))\n",
    "        Y = np.zeros((x.shape[0] - win - h, x.shape[1]))\n",
    "\n",
    "        for i in range(win, x.shape[0] - h):\n",
    "            ## Целевое значение/подпись рассчитывается через\n",
    "            ## h шагов вперед\n",
    "            y_i = x[i + h - 1     , :]\n",
    "            x_i = x[(i - win) : i , :]\n",
    "\n",
    "            X[i-win] = x_i\n",
    "            Y[i-win] = y_i\n",
    "\n",
    "        return (X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aY5sDqkD1lFk",
   "metadata": {
    "id": "aY5sDqkD1lFk"
   },
   "source": [
    "После считывания данных из текстового файла проводится стандартизация каждого столбца. Обратите внимание, что столбцы стандартизируются раздельно, а не однородно по всему набору данных. А все потому, что даже в нашем простом исследовании ясно видно, что данные для электростанций сильно разнятся."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y9VzpfaI3qp9",
   "metadata": {
    "id": "Y9VzpfaI3qp9"
   },
   "source": [
    "# Определим модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eJ4BoQ2b3wPm",
   "metadata": {
    "id": "eJ4BoQ2b3wPm"
   },
   "outputs": [],
   "source": [
    "################\n",
    "## MODELS ##\n",
    "################\n",
    "\n",
    "def fc_model(iter_train, input_feature_shape, X, Y,\n",
    "             win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    output = mx.sym.FullyConnected(data=X, num_hidden=20)\n",
    "    output = mx.sym.Activation(output, act_type = 'relu')\n",
    "    output = mx.sym.FullyConnected(data=output, num_hidden=10)\n",
    "    output = mx.sym.Activation(output, act_type = 'relu')\n",
    "    output = mx.sym.FullyConnected(data=output, num_hidden=321)\n",
    "\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])\n",
    "\n",
    "def cnn_model(iter_train, input_feature_shape, X, Y,\n",
    "              win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    conv_input = mx.sym.reshape(data=X, shape=(0, 1, win, -1))\n",
    "    ## Convolution expects 4d input (N x channel x height x width)\n",
    "    ## in our case channel = 1 (similar to a black and white image\n",
    "    ## height = time and width = channels slash electric locations\n",
    "\n",
    "    cnn_output = mx.sym.Convolution(data=conv_input,\n",
    "                                    kernel=(sz_filt,\n",
    "                                            input_feature_shape[2]),\n",
    "                                    num_filter=n_filter)\n",
    "    cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "    cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output,\n",
    "                                                 axes=(0, 2, 1, 3)),\n",
    "                                shape=(0, 0, 0))\n",
    "    cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "\n",
    "    output = mx.sym.FullyConnected(data=cnn_output,\n",
    "                                   num_hidden=input_feature_shape[2])\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])\n",
    "\n",
    "\n",
    "def rnn_model(iter_train, input_feature_shape, X, Y,\n",
    "              win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "    rnn_cells.add(mx.rnn.GRUCell(num_hidden=RNN_UNITS))\n",
    "    rnn_cells.add(mx.rnn.DropoutCell(drop))\n",
    "    outputs, _ = rnn_cells.unroll(length=win, inputs=X, merge_outputs=False)\n",
    "    rnn_output = outputs[-1] # only take value from final unrolled cell for use later\n",
    "\n",
    "    output = mx.sym.FullyConnected(data=rnn_output, num_hidden=input_feature_shape[2])\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])\n",
    "\n",
    "## simplifications to\n",
    "## https://github.com/apache/incubator-mxnet/blob/master/example/multivariate_time_series/src/lstnet.py\n",
    "def simple_lstnet_model(iter_train,  input_feature_shape, X, Y,\n",
    "                        win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    ## must be 4d or 5d to use padding functionality\n",
    "    conv_input = mx.sym.reshape(data=X, shape=(0, 1, win, -1))\n",
    "\n",
    "    ## convolutional element\n",
    "    ## we add padding at the end of the time win\n",
    "    cnn_output = mx.sym.pad(data=conv_input,\n",
    "                            mode=\"constant\",\n",
    "                            constant_value=0,\n",
    "                            pad_width=(0, 0,\n",
    "                                       0, 0,\n",
    "                                       0, sz_filt - 1,\n",
    "                                       0, 0))\n",
    "    cnn_output = mx.sym.Convolution(data=cnn_output,\n",
    "                                    kernel=(sz_filt,\n",
    "                                            input_feature_shape[2]),\n",
    "                                    num_filter=n_filter)\n",
    "    cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "    cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output,\n",
    "                                                 axes=(0, 2, 1, 3)),\n",
    "                                shape=(0, 0, 0))\n",
    "    cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "\n",
    "    ## recurrent element\n",
    "    stacked_rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "    stacked_rnn_cells.add(mx.rnn.GRUCell(num_hidden=RNN_UNITS))\n",
    "    outputs, _ = stacked_rnn_cells.unroll(length=win,\n",
    "                                          inputs=cnn_output,\n",
    "                                          merge_outputs=False)\n",
    "    rnn_output = outputs[-1] # only take value from final unrolled cell for use later\n",
    "    n_outputs = input_feature_shape[2]\n",
    "    cnn_rnn_model = mx.sym.FullyConnected(data=rnn_output,\n",
    "                                          num_hidden=n_outputs)\n",
    "\n",
    "    ## ar element\n",
    "    ar_outputs = []\n",
    "    for i in list(range(input_feature_shape[2])):\n",
    "        ar_series = mx.sym.slice_axis(data=X,\n",
    "                                      axis=2,\n",
    "                                      begin=i,\n",
    "                                      end=i+1)\n",
    "        fc_ar = mx.sym.FullyConnected(data=ar_series, num_hidden=1)\n",
    "        ar_outputs.append(fc_ar)\n",
    "    ar_model = mx.sym.concat(*ar_outputs, dim=1)\n",
    "\n",
    "    output = cnn_rnn_model + ar_model\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_yzNMo1MDYu",
   "metadata": {
    "id": "J_yzNMo1MDYu"
   },
   "source": [
    "# Настройка параметров обучения и создание системы учета\n",
    "Особенности различных моделей мы обсудим в последующих разделах и пока что пропустим ту часть кода, которая отвечает за построение графиков, а перейдем непосредственно к рассмотрению кода обучения и ведения учета.\n",
    "Ниже приведен код реализации процедуры обучения на доступных для изучения примерах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vSxKRyV5MF68",
   "metadata": {
    "id": "vSxKRyV5MF68"
   },
   "outputs": [],
   "source": [
    "## courtesy of https://www.saltycrane.com/blog/2007/11/python-circular-buffer/\n",
    "class RingBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.data = [0 for i in range(size)]\n",
    "\n",
    "    def append(self, x):\n",
    "        self.data.pop(0)\n",
    "        self.data.append(x)\n",
    "\n",
    "    def get(self):\n",
    "        return self.data\n",
    "\n",
    "def train(symbol, iter_train, valid_iter, iter_test,\n",
    "          data_names, label_names,\n",
    "          save_dir, gpu):\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "    printFile = open(os.path.join(SAVE_DIR, 'log.txt'), 'w')\n",
    "    def print_to_file(msg):\n",
    "        print(msg)\n",
    "        print(msg, file = printFile, flush = True)\n",
    "    print_to_file('Epoch     Training Cor     Validation Cor')\n",
    "    buf     = RingBuffer(THRESHOLD_EPOCHS)\n",
    "    old_val = None\n",
    "\n",
    "    devs   = mx.cpu()\n",
    "    module = mx.mod.Module(symbol,\n",
    "                           data_names=data_names,\n",
    "                           label_names=label_names,\n",
    "                           context=devs)\n",
    "    module.bind(data_shapes=iter_train.provide_data,\n",
    "                label_shapes=iter_train.provide_label)\n",
    "    module.init_params(mx.initializer.Uniform(0.1))\n",
    "    module.init_optimizer(optimizer='adam',\n",
    "                          optimizer_params={'learning_rate': LR})\n",
    "\n",
    "    for epoch in range( N_EPOCHS):\n",
    "        iter_train.reset()\n",
    "        iter_val.reset()\n",
    "        for batch in iter_train:\n",
    "            module.forward(batch, is_train=True)\n",
    "            module.backward()\n",
    "            module.update()\n",
    "\n",
    "        train_pred  = module.predict(iter_train).asnumpy()\n",
    "        train_label = iter_train.label[0][1].asnumpy()\n",
    "        train_perf  = evaluate_and_write(train_pred, train_label,\n",
    "                                      save_dir, 'train', epoch)\n",
    "\n",
    "        val_pred  = module.predict(iter_val).asnumpy()\n",
    "        val_label = iter_val.label[0][1].asnumpy()\n",
    "        val_perf = evaluate_and_write(val_pred, val_label,\n",
    "                                   save_dir, 'valid', epoch)\n",
    "\n",
    "        print_to_file('%d         %f       %f ' % (epoch, train_perf['COR'], val_perf['COR']))\n",
    "\n",
    "        if epoch > 0:\n",
    "            buf.append(val_perf['COR'] - old_val)\n",
    "        if epoch > 2:\n",
    "            vals = buf.get()\n",
    "            vals = [v for v in vals if v != 0]\n",
    "            if sum([v < COR_THRESHOLD for v in vals]) == len(vals):\n",
    "                print_to_file('EARLY EXIT')\n",
    "                break\n",
    "        old_val = val_perf['COR']\n",
    "\n",
    "    test_pred  = module.predict(iter_test).asnumpy()\n",
    "    test_label = iter_test.label[0][1].asnumpy()\n",
    "    test_perf = evaluate_and_write(test_pred, test_label, save_dir, 'tst', epoch)\n",
    "    print_to_file('\\n TESTING PERFORMANCE')\n",
    "    print_to_file(test_perf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YubzoZHTM5xj",
   "metadata": {
    "id": "YubzoZHTM5xj"
   },
   "source": [
    "## Зачем нужен кольцевой буфер\n",
    "Кольцевой буфер — это место для размещения значений, устроенное таким образом, что при их извлечении первый вход будет выступать первым выходом. Он имеет свойство расти только до заданного значения. Хотя производительность и объем памяти здесь не критичны, используя этот класс, можно избежать многих повторений.\n",
    "\n",
    "В языке Python нет встроенного кольцевого буфера, но вы можете найти простые примеры его реализации в Интернете. Его удобно применять для отслеживания небольшого количества значений в порядке их получения. Предыдущий код выполняет разнообразный набор рутинных задач. Во-первых, в нем устанавливаются значения, по которым отслеживается история показателей точности проверки, позволяющих убедиться в положительном прогрессе обучения. Если модель обучается недостаточно быстро, то не стоит продолжать нагружать графические процессоры, попусту тратя время и электроэнергию.\n",
    "\n",
    "В шаблоне MXNet задействован программный интерфейс Module (в отличие от Gluon, с которым мы имели дело ранее).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7z16MSlOM8ze",
   "metadata": {
    "id": "7z16MSlOM8ze"
   },
   "outputs": [],
   "source": [
    "\n",
    "## ЭТО ФРАГМЕНТ КОДА, А НЕ ПОЛНОЦЕННАЯ ЧАСТЬ ПРОГРАММЫ.\n",
    "\n",
    "## Шаблон mxnet\n",
    "## Значение по умолчанию - 1 GPU, индекс которого равен 0\n",
    "## devs = [mx.gpu(0)]\n",
    "## module = mx.mod.Module(symbol,\n",
    "##  \t\t\t\t\tdata_names=data_names,\n",
    "##  \t\t\t\t\tlabel_names=label_names,\n",
    "##  \t\t\t\t\tcontext=devs)\n",
    "## module.bind(data_shapes=iter_train.provide_data,label_shapes=iter_train.provide_label)\n",
    "## module.init_params(mx.initializer.Uniform(0.1))\n",
    "## module.init_optimizer(optimizer='adam', optimizer params={'learning_rate' :rgs.lr})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zTrZZQleNMF9",
   "metadata": {
    "id": "zTrZZQleNMF9"
   },
   "source": [
    "В приведенных выше строках кода выполняются следующее операции.\n",
    "1. Настройка компонента нейронной сети в виде вычислительного графа.\n",
    "2. Настройка формы данных так, чтобы позволить сети получить их и оптимизировать.\n",
    "3. Инициализация всех весов графа случайными значениями (это креативный процесс, а не просто случайный выбор чисел из бесконечного количества возможностей).\n",
    "4. Инициализация оптимизатора, который может иметь разные представления и для которого в явном виде устанавливается начальная скорость обучения в зависимости от входных параметров.\n",
    "Теперь воспользуемся итератором обучающих данных для прохода по данным во время обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JwFlWdYvNNjm",
   "metadata": {
    "id": "JwFlWdYvNNjm"
   },
   "outputs": [],
   "source": [
    "## ЭТО ФРАГМЕНТ КОДА, А НЕ ПОЛНОЦЕННАЯ ЧАСТЬ ПРОГРАММЫ.\n",
    "\n",
    "#  for epoch in range (args .n_epochs) :\n",
    "#  \titer_train.reset()\n",
    "#  \titer_val.reset()\n",
    "#  \tfor batch in iter_train:\n",
    "#  \t\tmodule.forward(batch, is_train=True) \t# вычисление прогнозов\n",
    "#  \t\tmodule.backward() \t\t\t\t# вычисление градиентов\n",
    "#  \t\tmodule.update()\t\t\t\t # обновление параметров\n",
    "# ## Оценим предсказанные результаты как для обучающего, так и для проверочного набора (в том же внешнем цикле for, что и раньше).\n",
    "#  ## Результаты обучения\n",
    "# train_pred = module.predict(iter_train).asnumpy()\n",
    "# train_label ~ iter_train.label[0][1].asnumpy()\n",
    "# train_perf = evaluate_and_write(train_pred, train_label,save_dir, 'train', epoch)\n",
    "#  ##Результаты проверки\n",
    "# val_pred = module.predict(iter_val).asnumpy()\n",
    "# val_label = iter_val.label[0][1].asnumpy()\n",
    "# val_perf = evaluate_and_write(val_pred, val_label,\tsave_dir, 'valid', epoch)\n",
    "# ## Следующий цикл проверяет условия досрочного прекращения обучения.\n",
    "# ## Python\n",
    "# if epoch > 0:\n",
    "#   buf .append(val_perf ['COR'] - old_val)\n",
    "# if epoch > 2:\n",
    "#   vals = buf. get ()\n",
    "#   vals = [v for v in vals if v != 0]\n",
    "#   if sum( [v < COR—THRESHOLD for v in vals]) == len (vals):\n",
    "#     print_to_file ( ' EARLY EXIT' )\n",
    "#     break\n",
    "# old_val = val_perf ['COR' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4BkXBNfkNkEk",
   "metadata": {
    "id": "4BkXBNfkNkEk"
   },
   "source": [
    "Этот громоздкий код позволяет вести учет выполненных действий и проверять условия, записывая каждое последующее значение корреляции между прогнозируемыми и фактическими значениями. Если поэтапная корреляция не демонстрирует улучшений (или даже показывает ухудшение) для заданного количества повторений, то обучение прекращается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9h95vrH0NlGr",
   "metadata": {
    "id": "9h95vrH0NlGr"
   },
   "source": [
    "# Оценка производительности\n",
    "Функция evaluate_and_write() фиксирует корреляцию, необработанные и оценочные значения на каждом вычислительном этапе. Она понадобится нам для тестирования в конце всего обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cXZau5CdNmmv",
   "metadata": {
    "id": "cXZau5CdNmmv"
   },
   "outputs": [],
   "source": [
    "def evaluate_and_write (pred, label, save_dir, mode, epoch):\n",
    "\tif not os.path.exists(save_dir):\n",
    "\t\tos .makedirs (save_dir)\n",
    "\tpred_df = pd. DataFrame (pred)\n",
    "\tlabel_df = pd.DataFrame(label)\n",
    "\tpred_df. to_csv ( os .path.join (save_dir, ' %s_pred%d. csv'\n",
    "\t\t\t\t\t% (mode, epoch) ) )\n",
    "\tlabel_df. to_csv (os .path.join (save_dir, ' %s_label%d. csv'\n",
    "\t\t\t\t\t% (mode, epoch) ) )\n",
    "\treturn { 'COR': COR (label, pred) }\n",
    "## В ней, в свою очередь, применяется корреляционная функция, определенная следующим образом.\n",
    "def COR (label, pred) :\n",
    "\tlabel_demeaned = label - label .mean (0)\n",
    "\tlabel_sumsquares = np.sum(np.square(label_demeaned), 0)\n",
    "\tpred_demeaned = pred - pred.mean(0)\n",
    "\tpred_sumsquares = np.sum(np.square(pred_demeaned), 0)\n",
    "\tcor_coef = np.diagonal(np.dot(label_demeaned.T, pred_demeaned)) / np.sqrt(label_sumsquares * pred_sumsquares)\n",
    "\treturn np.nanmean(cor_coef)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b_dsLYYLNvne",
   "metadata": {
    "id": "b_dsLYYLNvne"
   },
   "source": [
    "Иногда в этом наборе данных встречаются случаи нулевой дисперсии, которые могут привести к получению значений NAN в столбце, что обусловливает выбор функции np. nanmean() вместо np.mean().\n",
    "\n",
    "Обратите внимание, что одна из основных возможностей, которые здесь исключаются, — сохранение весов модели в контрольных точках на протяжении всего процесса обучения. При подготовке к производству нам нужно было иметь возможность перезагрузить модель и развернуть ее, для чего используются функции Module.save_checkpoint (сохранение весов) и Module.load (загрузка модели обратно в память для продолжения обучения или разворачивания производства). Существует много вариантов обучения принципам настройки правильного конвейера глубокого обучения, здесь мы рассматриваем только основные моменты.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92rmj35uN7Vt",
   "metadata": {
    "id": "92rmj35uN7Vt"
   },
   "source": [
    "# Сборка\n",
    "Объединим компоненты конвейера в теле метода__ main__ ().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "iV0S5qC5N9yS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV0S5qC5N9yS",
    "outputId": "cfca7194-03e4-4ebf-968c-406d82d018d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Cor     Validation Cor\n",
      "0         0.050538       0.042958 \n",
      "1         0.081092       0.073837 \n",
      "2         0.114391       0.106274 \n",
      "3         0.151711       0.142185 \n",
      "4         0.191893       0.181177 \n",
      "5         0.233721       0.221700 \n",
      "6         0.276049       0.262244 \n",
      "7         0.317783       0.301721 \n",
      "8         0.358097       0.339439 \n",
      "9         0.396407       0.374851 \n",
      "10         0.432237       0.407742 \n",
      "11         0.464966       0.438214 \n",
      "12         0.494531       0.466569 \n",
      "13         0.521001       0.492706 \n",
      "14         0.544741       0.516506 \n",
      "15         0.565792       0.538442 \n",
      "16         0.583968       0.558527 \n",
      "17         0.599062       0.575491 \n",
      "18         0.611520       0.590109 \n",
      "19         0.622625       0.603186 \n",
      "20         0.631457       0.613753 \n",
      "21         0.637900       0.621528 \n",
      "22         0.642454       0.627392 \n",
      "23         0.645507       0.631940 \n",
      "24         0.647542       0.635464 \n",
      "EARLY EXIT\n",
      "\n",
      " TESTING PERFORMANCE\n",
      "{'COR': 0.6299351}\n"
     ]
    }
   ],
   "source": [
    "# create data iterators\n",
    "iter_train, iter_val, iter_test = prepare_iters(DATA_FILE, WIN, H, MODEL, BATCH_N)\n",
    "\n",
    "## prepare symbols\n",
    "input_feature_shape = iter_train.provide_data[0][1]\n",
    "X                   = mx.sym.Variable(iter_train.provide_data[0].name)\n",
    "Y                   = mx.sym.Variable(iter_train.provide_label[0].name)\n",
    "\n",
    "# set up model\n",
    "model_dict = {\n",
    "    'fc_model'            : fc_model,\n",
    "    'rnn_model'           : rnn_model,\n",
    "    'cnn_model'           : cnn_model,\n",
    "    'simple_lstnet_model' : simple_lstnet_model\n",
    "    }\n",
    "\n",
    "model = model_dict[MODEL]\n",
    "\n",
    "symbol, data_names, label_names = model(iter_train,\n",
    "                                        input_feature_shape, X, Y,\n",
    "                                        WIN, SZ_FILT,\n",
    "                                        N_FILT, DROP, SEASONAL_PERIOD)\n",
    "\n",
    "## train\n",
    "train(symbol, iter_train, iter_val, iter_test, data_names, label_names, SAVE_DIR, GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyOqj_87OKWj",
   "metadata": {
    "id": "hyOqj_87OKWj"
   },
   "source": [
    "Здесь использована инфраструктура, созданная выше. Сначала анализируются аргументы командной строки. После этого создаются итераторы с настраиваемыми входными данными, включая горизонт прогнозирования, окно обратного просмотра, размер пакета и имя создаваемой модели. Далее создаются символы MXNet, а также записывается форма входных данных, востребованная при создании модели. Наконец, информация о модели вместе с итераторами и каталогом сохранения передается в функцию обучения, которая выполняет наиболее интересную часть: обучает модель и выводит показатели производительности.\n",
    "\n",
    "Таким образом, мы можем наблюдать минимальный, но полностью функциональный конвейер обучения, включающий прием и изменение данных, построение и обучение модели, а также запись важных показателей для правильной ее оценки. Кстати, метод print_to_file () — это всего лишь удобная оболочка для функции print().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1DQhfuoLOK0q",
   "metadata": {
    "id": "1DQhfuoLOK0q"
   },
   "outputs": [],
   "source": [
    "## ЭТО ФРАГМЕНТ КОДА, А НЕ ПОЛНОЦЕННАЯ ЧАСТЬ ПРОГРАММЫ.\n",
    "# def print_to_file (msg):\n",
    "#   print (msg, file = printFile, flush = True)\n",
    "# print_to_file(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3GSw7Q3cOVha",
   "metadata": {
    "id": "3GSw7Q3cOVha"
   },
   "source": [
    "Вам может понадобиться сохранить процесс обучения модели. Вполне возможно, что подобранные веса модели окажутся не теми, на которых завершился сеанс обучения, а получены несколько ранее. Наличие записи о ходе обучения поможет точнее настроить гиперпараметры, относящиеся как к структуре модели, так и к процессу обучения, начиная с их количества (во избежание недо-или переобучения) и заканчивая скоростью обучения (для предотвращения слишком сильных или слабых корректировок).\n",
    "\n",
    "На данный момент мы располагаем полным, хотя и минимальным, жизнеспособным конвейером, но нам все еще не хватает моделей для обучения. Далее мы перейдем к рассмотрению основных типов моделей, применимых в анализе временных рядов, и обучим каждую из них, чтобы оценить относительную производительность.\n",
    "# Сети прямого распространения\n",
    "В этом разделе предпринят довольно необычный прием, который заключается в использовании сетей прямого распространения для анализа временных рядов. Большинство современных задач обработки данных временных рядов основано на рекуррентных или, несколько реже, сверточных нейронных сетях. Однако мы начнем наш экскурс с нейронной сети прямого распространения, так как она имеет самую простую структуру. Существует несколько причин, по которым дальнейший материал целесообразно начинать рассматривать именно с нейронных сетей прямого распространения.\n",
    "\n",
    "- Сети прямого распространения допускают очень простое распараллеливание, а значит, обладают высокой производительностью. Получив в свое распоряжение достаточно хорошую модель прямого распространения, вы сможете вычислить ее очень быстро.\n",
    "- Сети прямого распространения прекрасно подходят для оценки сложности динамических процессов в анализируемой временной последовательности. Не все временные ряды действительно являются временными в том понимании, что не во всех них динамические изменения демонстрируют временную направленность — более ранние значения имеют определенную связь с более поздними значениями. Нейронную сеть прямого распространения желательно использовать в качестве одной из базовых моделей наряду с простой линейной моделью.\n",
    "- Компоненты сетей прямого распространения часто интегрируются в более крупные и сложные архитектуры глубокого обучения временных рядов. Поэтому крайне важно понять, как они работают, даже если они не образуют целостную модель для вашего проекта.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2EVyR-poOafK",
   "metadata": {
    "id": "2EVyR-poOafK"
   },
   "source": [
    "# Простой пример\n",
    "Сеть прямого распространения — это простейший тип нейронной сети, и мы начнем ее изучение с примера использования архитектуры прямого распространения к некому временному ряду. В структуре стандартной нейронной сети прямого распространения нет ничего, указывающего на временные отношения, но идея заключается в том, чтобы позволить алгоритму понять, как по прошлым входным данным предсказать будущие данные. Пример сети прямого распространения приведен на рис. 9.1. Сеть прямого распространения представляет собой ряд полносвязных слоев, т.е. входные данные каждого слоя подключаются к каждому узлу графа.\n",
    "\n",
    "Начнем изучение с простого примера с уже известным способом форматирования данных. Иначе говоря, наши входные данные X будут представлены двумерными значениями N х С (т.е. выборки х каналы), где временные компоненты упорядочены в каналах. Это соответствует следующему формату данных.\n",
    "\n",
    "A,t-2 \tA,t-3 \tВ,t-2 \tB,t-3 \tС,t-2 \tC,t-3\n",
    "\n",
    "J \t0\t-2\t-1\t-3\t-2\n",
    "\n",
    "Напомним код, который представляет эту ветвь данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "JlHZzeUsOdP5",
   "metadata": {
    "id": "JlHZzeUsOdP5"
   },
   "outputs": [],
   "source": [
    "## ЭТО ФРАГМЕНТ КОДА, А НЕ ПОЛНОЦЕННАЯ ЧАСТЬ ПРОГРАММЫ.\n",
    "\n",
    "# if model_name == 'fc_model':\n",
    "# ## Первый и второй обратные шаги в исходных данных\n",
    "#   X = np.hstack([х[1:-1], х[:—2] ])\n",
    "#   Y = х[2: ]\n",
    "#   return (X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Smx2sx7qOorD",
   "metadata": {
    "id": "Smx2sx7qOorD"
   },
   "source": [
    "Создадим полносвязную модель с помощью программного интерфейса Module пакета MXNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "RO9mCUeCOukF",
   "metadata": {
    "id": "RO9mCUeCOukF"
   },
   "outputs": [],
   "source": [
    "def fc_model(iter_train, input_feature_shape, X, Y,\n",
    "             win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    output = mx.sym.FullyConnected(data=X, num_hidden=20)\n",
    "    output = mx.sym.Activation(output, act_type = 'relu')\n",
    "    output = mx.sym.FullyConnected(data=output, num_hidden=10)\n",
    "    output = mx.sym.Activation(output, act_type = 'relu')\n",
    "    output = mx.sym.FullyConnected(data=output, num_hidden=321)\n",
    "\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tmIdxhEiOxFC",
   "metadata": {
    "id": "tmIdxhEiOxFC"
   },
   "source": [
    "Мы строим трехслойную полносвязную сеть. Первый слой имеет 20 скрытых элементов, а второй слой  10. После первых двух слоев добавлен слой активации. Именно он делает модель нелинейной. Без него она представляет последовательность произведений матриц и сводится к линейной модели. Полносвязный слой имеет вид Y = XWT + b, где W - это набор весов, соответствующих таковому в произведении матриц с исправленными размерностями, результатом которого будет вектор, учитывающий скрытые значения. Затем к нему добавляется сдвиг. Веса W и сдвиг b уточняются в ходе обучения. Заметьте, что обучение одного такого набора весов или даже серии таких весов не представляет большого интереса - это просто другой способ вычисления линейной регрессии. Однако активация, включаемая в модель после матричных операций, предопределяет разнообразие. Слой активации основан на различных нелинейных функциях, таких как tanh и ReLU, графики которых изображены на рис. 9.5 и 9.6 соответственно. В предыдущем коде в качестве функции активации использована функция ReLU. В общем случае имеет смысл тестировать различные функции активации (ReLU, tanh, сигмоида) на ранних стадиях построения модели и настройки гиперпараметра.\n",
    "\n",
    "![data](picture2.png)\n",
    "\n",
    "*Рис. 9.5 Функция tank демонстрирует нелинейное поведение на небольшом интервале, а затем становится постоянной и характеризуется нулевой производной* \n",
    "\n",
    "![data](picture3.png)\n",
    "\n",
    "*Рис. 9.6 Функция ReLU проста для вычисления, но также привносит нелинейность*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e7046df-8045-4af6-995d-bb5a3e761104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Cor     Validation Cor\n",
      "0         0.034097       0.027782 \n",
      "1         0.063353       0.061984 \n",
      "2         0.089801       0.094201 \n",
      "3         0.119641       0.126777 \n",
      "4         0.157136       0.164193 \n",
      "5         0.197003       0.203099 \n",
      "6         0.238220       0.244085 \n",
      "7         0.279969       0.286885 \n",
      "8         0.322683       0.332218 \n",
      "9         0.364146       0.376944 \n",
      "10         0.408795       0.425110 \n",
      "11         0.451955       0.470087 \n",
      "12         0.494068       0.517032 \n",
      "13         0.527080       0.553799 \n",
      "14         0.548743       0.578174 \n",
      "15         0.564526       0.595459 \n",
      "16         0.578733       0.609722 \n",
      "17         0.592024       0.623829 \n",
      "18         0.599834       0.632311 \n",
      "19         0.605807       0.638662 \n",
      "20         0.610867       0.643897 \n",
      "21         0.615355       0.648192 \n",
      "22         0.619343       0.651717 \n",
      "EARLY EXIT\n",
      "\n",
      " TESTING PERFORMANCE\n",
      "{'COR': 0.6135147}\n"
     ]
    }
   ],
   "source": [
    "iter_train, iter_val, iter_test = prepare_iters(DATA_FILE, WIN, H, 'fc_model', BATCH_N)\n",
    "input_feature_shape = iter_train.provide_data[0][1]\n",
    "X                   = mx.sym.Variable(iter_train.provide_data[0].name)\n",
    "Y                   = mx.sym.Variable(iter_train.provide_label[0].name)\n",
    "model = model_dict['fc_model']\n",
    "symbol, data_names, label_names = model(iter_train,\n",
    "                                        input_feature_shape, X, Y,\n",
    "                                        WIN, SZ_FILT,\n",
    "                                        N_FILT, DROP, SEASONAL_PERIOD)\n",
    "train(symbol, iter_train, iter_val, iter_test, data_names, label_names, SAVE_DIR, GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r4BeVXdVO4G1",
   "metadata": {
    "id": "r4BeVXdVO4G1"
   },
   "source": [
    "Теперь давайте обучим нашу модель и посмотрим, как она работает. Это хорошая точность? Трудно сказать, не зная контекста задачи. Работая с моделью глубокого обучения, вы должны запустить ее в производство, только если она значительно превосходит более простые модели, рассматриваемые в предыдущих разделах. Модель глубокого обучения требует больше времени для расчета и, как правило, выдвигает более высокие требования к вычислительным ресурсам, поэтому ее следует использовать только при полной оправданности производственных затрат. По этой же причине, выполняя задачи анализа временных рядов с помощью инструментов глубокого обучения, сначала попробуйте обратиться к более простым моделям, которые послужат объективным стандартом в достижении цели.\n",
    "\n",
    "В любом случае нам удалось показать, что даже модель без явно выраженной временной направленности способна обучаться и составлять прогнозы, которые правдоподобно коррелируют с измеренными значениями.\n",
    "# Внимание как фактор улучшения сетей прямого распространения\n",
    "Хотя сети прямого распространения не показывают хороших результатов в решении задач анализа временных рядов, исследователями ведутся работы по разработке архитектур с повышенной точностью обработки последовательных данных. Одна из рассматриваемых ими концепций основана на понятии внимания, которое обозначает механизмы нейронной сети, позволяющие определить ту часть последовательности, которая требует наибольшего сосредоточения и вносит наибольший вклад в получение желаемого результата.\n",
    "\n",
    "Понятие внимания предполагает, что архитектура нейронной сети должна снабжать модель механизмами определения наиболее важной информации на каждом временном этапе. Это достигается с помощью весов внимания, которые настраиваются отдельно для каждого временного шага, позволяя модели комбинировать информацию с разных временных шагов. Такие веса внимания умножаются на то, что в противном случае считается выходным, либо скрытым, состоянием модели, преобразуя это скрытое состояние в вектор контекста, название которого указывает на то, что скрытое состояние теперь лучше учитывает весь временной контекст информации, содержащейся во временных рядах и подлежащей описанию с помощью неких временных зависимостей.\n",
    "Функция Softmax()\n",
    "Возможно, вы уже знакомы с функцией\n",
    "![data](picture4.png)\n",
    "которая служит двум целям:\n",
    "\n",
    "- Сделать сумму выходов равной единице, чтобы представить полный набор вероятностей. Часто результат работы функции softmax() интерпретируется именно так.\n",
    "- \n",
    "- Принимая во внимание общую форму экспоненциальной функции, сделать большие входные данные (у.) еще большими, а меньшие входные данные еще больше уменьшить. Такой подход позволяет подчеркнуть сильные активации/веса и погасить слабые сигналы.\n",
    "\n",
    "Функция softmax() также известна как нормализованная экспоненциальная функция  такое название предопределяется формой ее математической записи, приведенной выше.\n",
    "\n",
    "Исходно концепция внимания стала использоваться в рекуррентных нейронных сетях (подробнее об этом  далее), но понять ее назначение и принципы реализации проще всего на примере архитектуры прямого распространения, приведенном в исследовательской работе https: //arxiv.org/pdf/1512.08756.pdf. В этом документе рассматривается такой способ применения нейронных сетей прямого распространения к последовательным данным, в котором реакция сети на каждый шаг последовательности передается на вход и таким образом влияет на получаемый результат. Такой подход позволяет обрабатывать последовательности переменной длины, ведь временные ряды переменной длины являются типичными для практических задач.\n",
    "\n",
    "На рис. 9.7 представлен пример того, как нейронная сеть прямого распространения может использоваться для решения задачи обработки последовательных данных.\n",
    "\n",
    "Сеть прямого распространения применяется к входам на каждом временном шаге отдельно, генерируя “скрытое состояние” для каждого временного шага  . В результате формируется ряд скрытых состояний. Показанная в углу вторая нейронная сеть, разработанная для обучения  , представляет механизм внимания. Он позволяет узнать, какой вес приписать каждому входу, причем на вход передается состояние, взятое для другого момента времени. Это позволяет механизму определить веса для каждого временного шага в окончательной сумме входных данных.\n",
    "\n",
    "![data](picture5.png)\n",
    "\n",
    "*Рис. 9.7. Механизм внимания в сети прямого распространения*\n",
    "\n",
    "Впоследствии скрытые состояния разных временных этапов объединяются с соответствующими коэффициентами внимания перед окончательной обработкой, чтобы определить целевое значение/подпись. Разработчики такой сети обнаружили, что она отлично справляется с различными задачами, которые до этого решались исключительно с помощью рекуррентных нейронных сетей, в полной мере удовлетворяющих требованиям к запоминанию более ранних входных данных и объединения их с более поздними данными.\n",
    "\n",
    "Этот пример наглядно показывает, что модели глубокого обучения не имеют простых архитектур ввиду большого количества возможностей по адаптации даже базовой модели к целевым задачам анализа временных рядов.\n",
    "\n",
    "Как уже отмечалось, нейронные сети прямого распространения не являются основными инструментами решения задач, связанных с обработкой данных временных рядов. Тем не менее они послужат хорошей отправной точкой на пути к оценке точности простых моделей. Интересно, что если не добавлять функцию активации, то можно использовать их для реализации моделей AR и VAR с помощью фреймворка MXNet. Иногда они, правда, применяются в чистом виде. Что более важно, существуют архитектурные решения полносвязных моделей, которые оказываются необычайно точными для определенных наборов временных рядов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YTGzV-QmO-UG",
   "metadata": {
    "id": "YTGzV-QmO-UG"
   },
   "source": [
    "# Сверточные нейронные сети\n",
    "Если вы знакомы с глубоким обучением, то, скорее всего, имеете представление о сверточных нейронных сетях (Convolutional Neural Networks — CNN). Большая часть выдающихся, сравнимых с возможностями человеческого мозга, достижений, которые приписываются компьютерам, за последние годы, получены благодаря чрезвычайно запутанной и сложной сверточной архитектуре.\n",
    "\n",
    "Несмотря на все это, принципы построения свертки довольно просты и были разработаны задолго до появления глубокого обучения. Свертки давно применяются в более простых, управляемых человеком, системах обработки и распознавания изображений, например в таких простых фильтрах, как гауссово размытие. Все, кто не знакомы с устройством ядер обработки изображений и не представляют, как они пишутся, могут найти хорошее описание принципов их построения на сайте Stack Overflow (https: //perma.cc/8U8Y-RBYW) - как с помощью высокоуровневого программного интерфейса, так и вручную с использованием инструментов библиотеки NumPy.\n",
    "\n",
    "Свертка означает такое применение ядра (матрицы) к более крупной матрице, в котором она как бы “скользит” по большей матрице, образуя новую. Каждый элемент новой матрицы представляет собой сумму поэлементного произведения ядра и фрагмента большей матрицы. Такое ядро применяется неоднократно в процессе “скольжения” по матрице/изображению. Это делается для заранее оговоренного количества ядер для проявления различных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6875984-83ee-410f-91f3-a95b0397de7a",
   "metadata": {},
   "source": [
    "Принципиальная схема сверточной сети на многослойных структурах приведена на рис. 9.8.\n",
    "\n",
    "![data](picture6.png)\n",
    "\n",
    "*Рис. 9.8. Сверточная сеть*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca50e87-2d9d-4326-9385-eb03cf073835",
   "metadata": {},
   "source": [
    "По многим причинам традиционная сверточная сеть плохо подходит для работы с временными рядами. Главная особенность сверток состоит в одинаковости обработки всех пространств, что имеет смысл при работе с изображениями, но не с временными рядами, в которых некоторые отдельные временные точки обязательно находятся ближе, чем другие. Сверточные сети обычно имеют масштабно-инвариантную структуру, что позволяет достаточно точно сказать, например, что на рисунке изображена лошадь, независимо от того, насколько она большая. Однако во временных рядах по большей части масштаб, как и масштабируемые признаки, остается неизменным. Годовое сезонное колебание не должно интерпретироваться так же или описываться тем же набором признаков, что и дневное колебание, хотя в некоторых случаях это очень даже целесообразно.\n",
    "\n",
    "Именно такая двойственная природа сверток - сильные стороны одновременно могут быть как преимуществом, так и недостатком  приводит к тому, что они все чаще выступают отдельными компонентами сети (а не отдельной сетью),предназначенной для анализа временных рядов. Кроме того, это их свойство стало причиной более частого использования сверток для решения задач классификации, чем прогнозирования, хотя достойное применение находят оба варианта.\n",
    "\n",
    "Перечислим наиболее востребованные способы использования сверточных сетей для анализа временных рядов.\n",
    "\n",
    "- Определение “характерных признаков” в истории посещений интернет-ресурсов, что помогает обнаружить аномальную активность пользователей в Интернете.\n",
    "  \n",
    "- Выявление необычных сердечных ритмов по данным ЭКГ.\n",
    "  \n",
    "- Предсказание транспортных потоков по записям с камер, установленных в нескольких местах большого города.\n",
    "  \n",
    "Применимо к одномерным временным рядам свертки не могут представить ничего интересного. Их значимость проявляется при проведении анализа многоканальных временных рядов, поскольку в них приходится работать в двумерных (или даже в трехмерных) пространствах, в которых время — только одна из осей.\n",
    "\n",
    "Есть и другие архитектурные новшества, о которых стоит упомянуть в силу рассмотрения в следующем разделе двух примеров сверточных механизмов для временных рядов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQ-c6RqOPEnl",
   "metadata": {
    "id": "EQ-c6RqOPEnl"
   },
   "source": [
    "## Простая сверточная модель\n",
    "Сверточную модель можно применить к имеющимся данным вместо описанной выше полносвязной модели. В этом и остальных примерах мы будем работать с данными в формате NTC, которые выглядят следующим образом.\n",
    "\n",
    "Время \tА \t\tВ \t\tС\n",
    "\n",
    "t-1\t\t0,3\t\t-1,-2\t\t-2,-3\n",
    "\n",
    "t\t\t3,4\t\t-2,-2\t\t-3,-4\n",
    "\n",
    "Как видите, данные представляются в виде N х Т х С. Однако сверточный слой предполагает получение данных в формате batch_size, channel,height х width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "AxxNxRfBPFaU",
   "metadata": {
    "id": "AxxNxRfBPFaU"
   },
   "outputs": [],
   "source": [
    "def cnn_model(iter_train, input_feature_shape, X, Y,\n",
    "              win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    conv_input = mx.sym.reshape(data=X, shape=(0, 1, win, -1))\n",
    "    ## Сверточная сеть работает с четырехмерными входными данными\n",
    "\t## (N х количествово каналов х высота х ширина)\n",
    "\t## в нашем случае канал один (как на черно-белом изображении,\n",
    "\t## где высота = время, ширина = расположение электростанций\n",
    "    cnn_output = mx.sym.Convolution(data=conv_input,\n",
    "                                    kernel=(sz_filt,\n",
    "                                            input_feature_shape[2]),\n",
    "                                    num_filter=n_filter)\n",
    "    cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "    cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output,\n",
    "                                                 axes=(0, 2, 1, 3)),\n",
    "                                shape=(0, 0, 0))\n",
    "    cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "\n",
    "    output = mx.sym.FullyConnected(data=cnn_output,\n",
    "                                   num_hidden=input_feature_shape[2])\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m7RrBgk3PNwh",
   "metadata": {
    "id": "m7RrBgk3PNwh"
   },
   "source": [
    "Снова-таки, представленная модель все еще не имеет явно заданной временной направленности. При этом время все же откладывается вдоль одной из осей, что делает модель более упорядоченной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9eaf0c8-304a-40c9-8185-da479f67a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Cor     Validation Cor\n",
      "0         0.017222       0.023929 \n",
      "1         0.029033       0.030811 \n",
      "2         0.041627       0.042931 \n",
      "3         0.054093       0.055953 \n",
      "4         0.068364       0.070664 \n",
      "5         0.085936       0.089567 \n",
      "6         0.106613       0.112421 \n",
      "7         0.130990       0.139529 \n",
      "8         0.160021       0.171280 \n",
      "9         0.194177       0.207753 \n",
      "10         0.232605       0.247638 \n",
      "11         0.274074       0.289593 \n",
      "12         0.316903       0.331936 \n",
      "13         0.358811       0.372446 \n",
      "14         0.398565       0.410066 \n",
      "15         0.435073       0.444040 \n",
      "16         0.467577       0.473650 \n",
      "17         0.495994       0.499087 \n",
      "18         0.520477       0.520532 \n",
      "19         0.541577       0.538527 \n",
      "20         0.559583       0.553461 \n",
      "21         0.575204       0.565975 \n",
      "22         0.588700       0.576445 \n",
      "23         0.600476       0.585296 \n",
      "24         0.610891       0.592926 \n",
      "25         0.620124       0.599446 \n",
      "26         0.628506       0.605269 \n",
      "27         0.636047       0.610274 \n",
      "28         0.642993       0.614785 \n",
      "29         0.649417       0.618865 \n",
      "EARLY EXIT\n",
      "\n",
      " TESTING PERFORMANCE\n",
      "{'COR': 0.59971404}\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'fc_model'            : fc_model,\n",
    "    'rnn_model'           : rnn_model,\n",
    "    'cnn_model'           : cnn_model,\n",
    "    'simple_lstnet_model' : simple_lstnet_model\n",
    "    }\n",
    "iter_train, iter_val, iter_test = prepare_iters(DATA_FILE, WIN, H, 'cnn_model', BATCH_N)\n",
    "input_feature_shape = iter_train.provide_data[0][1]\n",
    "X                   = mx.sym.Variable(iter_train.provide_data[0].name)\n",
    "Y                   = mx.sym.Variable(iter_train.provide_label[0].name)\n",
    "model = model_dict['cnn_model']\n",
    "symbol, data_names, label_names = model(iter_train,\n",
    "                                        input_feature_shape, X, Y,\n",
    "                                        WIN, SZ_FILT,\n",
    "                                        N_FILT, DROP, SEASONAL_PERIOD)\n",
    "train(symbol, iter_train, iter_val, iter_test, data_names, label_names, SAVE_DIR, GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddd57a-21d1-4ea7-9437-bda18fc9c10f",
   "metadata": {},
   "source": [
    "Зачастую очень трудно разобраться, почему одна модель лучше, другая - хуже. На самом деле даже сами разработчики моделей нередко ошибаются, определяя причины хороших результатов модели. Существует очень мало аналитических средств, позволяющих выяснить это предельно точно, а с учетом порой запутанной структуры входного набора данных — почти невозможно. Но разве отсутствие явных преимуществ модели CNN не указывает на то, что большая часть важной информации сосредоточена в ближайшие моменты времени? Или это отражается в количестве параметров? И как сказывается на точности модели количество используемых гиперпараметров? В реальных задачах критически важно понимать, какой уровень точности можно считать достаточным для заданных структуры модели, структуры данных и общего количества рассматриваемых параметров.\n",
    "\n",
    "Мы наблюдаем ошибку в коде, обусловленную избранной логикой ранней остановки. Похоже, она была слишком мягкой. В данном случае задача была пересмотрена, и мне удалось заметить, что в течение ряда этапов могут наблюдаться следующие изменения в корреляции.\n",
    "\n",
    "[-0,023024142, 0,03423196, -0,008353353, 0,009730637, -0,029091835]\n",
    "\n",
    "Такой результат означает, что изменение в корреляции может быть очень сильным — даже отрицательным — и многократно наблюдаемым, и тем не менее точность модели понемногу улучшается. Такая мягкость оказывается не самым хорошим решением, поэтому неплохо вернуться к конвейеру и задать более жесткие условия ранней остановки. Это только один из примеров компромисса, которые вы будете постоянно искать при использовании моделей глубокого обучения. Чтобы его достичь, вам придется выполнять много пробных прогонов для построения работоспособного конвейера. Таким образом можно получить представление о параметрах, приемлемых для целевого набора данных, и о представляющих интерес моделях, учитывая, что они существенно различаются от одного набора данных к другому.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3652f5-5fd7-4221-8a4e-47f8e5d7a166",
   "metadata": {},
   "source": [
    "## Альтернативные сверточные модели\n",
    "Простая сверточная модель, с которой вы познакомились выше, работала на удивление хорошо, хотя и не содержала никаких специальных модификаций, учитывающих временную направленность данных. Далее мы обсудим два подхода к использованию сверточных архитектур для анализа временных рядов: принятые в исследовательской и производственной средах.\n",
    "\n",
    "Почему сверточные сети столь привлекательны? На то есть множество причин. Во-первых, сверточные архитектуры — это проверенные, эффективные методы, которые хорошо изучены специалистам отрасли. Кроме того, у сверточных моделей мало параметров, так как одни и те же фильтры повторяются снова и снова, а это означает, что для обучения не требуется слишком много весов.\n",
    "\n",
    "И наконец, большие фрагменты сверточных моделей можно вычислить параллельно, т.е. они могут быть очень быстродействующими инструментами построения логических выводов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a597e2-9490-41d5-8c56-42f321ace2a7",
   "metadata": {},
   "source": [
    "## Причинные свертки\n",
    "Причинные свертки будем рассматривать на наглядных иллюстрациях, поскольку они проще всего могут продемонстрировать принципы модификации сверток для учета факторов причиной связи и течения времени. На рис. 9.9 показан пример расширенной причинной свертки (dilated causal convolution). Ее причинная компонента работает так, что в любой отдельно рассматриваемый сверточный фильтр попадают входы только за прошлые моменты времени. Вот почему изображение не симметрично: более ранние точки переходят в свертки, используемые в более поздние моменты времени, но не наоборот.\n",
    "\n",
    "![data](picture7.png)\n",
    "\n",
    "*Рис. 9.9 Граф, иллюстрирующий важную часть архитектуры WaveNet*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bc172-8d00-4b4d-8275-3f68ab5bc7a1",
   "metadata": {},
   "source": [
    "Компонента “расширения” отвечает за пропуск точек в структуре сверточных фильтров, так что на каждом слое любая заданная точка попадает только в один сверточный фильтр каждого слоя. Это способствует разреженности модели и уменьшает избыточные или перекрывающиеся свертки, позволяя модели учитывать предыдущую по времени информацию и в то же время поддерживать объем вычислений на приемлемом уровне.\n",
    "\n",
    "Приведенный пример расширенной причинной свертки основан на понятии временной причинности, разрешая только те данные, которые относятся к предыдущим моментам времени. Иначе говоря, свертки на этом изображении имеют неравные возможности: они позволяют передавать данные только из прошлого в будущее, а не наоборот. Каждая точка данных в исходном входе оказывает влияние на конечную точку. Обратите внимание, что именно здесь означает расширение: все более и более глубокие слои в свертке игнорируют все большее число точек, заданных в предыдущих слоях. В соответствии с тем, как организовано расширение, в окончательный вход включается каждая точка исходных данных, но только один раз. В принципе, для расширения это не является обязательным условием, но в данном случае задействован именно такой подход. Расширение можно организовать так, чтобы пропустить вообще все временные точки.\n",
    "\n",
    "Хотя причинные свертки кажутся сложными для понимания и расчета, реализовать их удивительно просто. Просто заполните левую часть матрицы пустыми значениями, т.е. добавьте в нее более ранние временные отступы, приравненные к нулю, чтобы они не влияли на значение, а затем предоставьте им статус “действительных”, чтобы свертка работала только в реальных границах матрицы, не затрагивая мнимые пустые ячейки. Учитывая, что свертки рассчитываются через суммирование поэлементных произведений, добавление нулей в левую часть рис. 9.9 позволит выполнить стандартную свертку так, что дополнительные нулевые ячейки не будут влиять на конечный результат.\n",
    "\n",
    "Причинные свертки имели большой успех в производственном секторе, в частности, как часть технологий компании Google, применяемой для преобразования текста в речь, а также для распознавания речи.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadb5a2-6cf2-4582-8a58-016a3d9c9922",
   "metadata": {},
   "source": [
    "## Преобразования временного ряда в изображения\n",
    "Известно, что сверточные модели очень хорошо показали себя в анализе изображений, и для того, чтобы попытаться в полной мере применить их к временным рядам, нужно найти способ приведения данных временного ряда к изображению. Существует много способов выполнения этой задачи, один из которых интересен тем, что позволяет преобразовать в рекуррентную диаграмму даже одномерный временной ряд (рис. 9.10).\n",
    "\n",
    "![data](picture8.png)\n",
    "\n",
    "*Рис. 9.10. Наглядная визуализация четырех видов временных рядов (слева направо): (а) белый шум, (6) гармонический/сезонный ряд с двумя частотами, (в) хаотические данные с трендом, (г) авторегрессионный процесс. Источник: Википедия, статья Норберта Марвана (2006) https://perma.cc/4BV2-57T4*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98db53-4a7e-4f7f-b3df-ce615870f6f4",
   "metadata": {},
   "source": [
    "Рекуррентная диаграмма — это способ описания состояний в фазовом пространстве, когда временной ряд возвращается примерно к той же фазе и состоянию, в котором он находился в более ранний момент времени. Эта диаграмма определяется через двоичную рекуррентную функцию. Рекурсия задается как R(i,j) = 1, если f(i) - f(j) достаточно мало, и 0 — в противном случае. Такое преобразование приводит к получению двоичного черно-белого изображения, подобного показанному на рис. 9.10. Обратите внимание, что индексы i и j относятся к значениям времени, а ось времени никак не ограничена.\n",
    "\n",
    "Несмотря на то что реализация рекуррентных диаграмм — это относительно простое занятие, в таких пакетах, как pyts (https: //perma.cc/4K5X-VYQR) предусмотрена специальная функция их построения, исходный код которой широко доступен для загрузки (https : //perma. cc/VS2Z-EJ8 J) и прост в использовании.\n",
    "\n",
    "Чтобы понять, как можно использовать описанный принцип для представления в виде изображения многомерного временного ряда, рассматривайте переменные такого ряда как отдельные цветовые каналы изображения. Это всего лишь один пример того, насколько универсальными и гибкими могут быть архитектура и методы глубокого обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DNjQJIBIPULn",
   "metadata": {
    "id": "DNjQJIBIPULn"
   },
   "source": [
    "# Рекуррентные нейронные сети\n",
    "Рекуррентные нейронные сети (Recurrent Neural Networks — RNN) представляют собой широкий класс сетей, в которых одни и те же параметры применяются повторно даже при изменении входных данных с течением времени. Они очень похожи на нейронные сети прямого распространения, описанные выше, но, как бы там ни было, на RNN основаны — полностью или частично — многие из наиболее успешных моделей, применяемых для решения научных и производственных задач, связанных с анализом последовательностей данных, обработкой языковых структур, а также с прогнозированием и классификацией временных рядов. Укажем на важные отличия RNN и сетей прямого распространения.\n",
    "\n",
    "- RNN рассматривает временные шаги по порядку.\n",
    "\n",
    "- RNN включает состояние, которое сохраняется неизменным от одного временного шага к другому, и именно это состояние, а также его статические параметры, определяют ответные обновления для каждой новой порции информации, получаемой на каждом шаге.\n",
    "\n",
    "- RNN включает параметры, которые позволяют пошагово обновлять свое состояние, включая скрытое состояние.\n",
    "\n",
    "Часто RNN описываются через парадигму развертывания, согласно которой рекуррентная архитектура основана на узлах. В такой парадигме предполагается, что одни и те же параметры используются снова и снова, а число параметров довольно мало даже для очень длинных временных последовательностей (рис. 9.11).\n",
    "\n",
    "![data](picture9.png)\n",
    "\n",
    "*Рис. 9.11. Развертывание рекуррентной нейронной сети на каждом временном шаге при обработке данных*\n",
    "\n",
    "Однако самый простой способ понять, как работает RNN, — это изучить простой пример. Моя самая любимая реализация RNN — управляемый рекуррентный блок (Gated Recurrent Unit — GRU). Его математическое описание выглядит сложнее, чем код реализации, поэтому ниже рассматривается вариант написания GRU на языке Python с помощью библиотеки NumPy. Как видите, в коде используются две функции активации: сигмоида и гиперболический тангенс. Кроме того, все, что делает код, — перемножает и суммирует матрицы, а также выполняет поэлементное умножение матриц (произведение Адамара)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "RAtHozjOPa8f",
   "metadata": {
    "id": "RAtHozjOPa8f"
   },
   "outputs": [],
   "source": [
    "## Используем веса, заимствованные из TensorFlow\n",
    "## https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnGRU\n",
    "## Его можно настроить на использование любых других весов\n",
    "def calc_gru(X, weights, num_inputs, num_features) :\n",
    "\tUs = weights[:(3*num_features*num_inputs)]\n",
    "\tUs = np.reshape (Us, [3, num_features, num_inputs])\n",
    "\tWs = weights[(3*num_features*num_inputs):(3*num_features*num_features +\n",
    "3*num_features*num_inputs)]\n",
    "\tWs = np.reshape (Ws, [3, num_features, num_features])\n",
    "\tBs = weights [(-6 * num_features) :]\n",
    "\tBs = np.reshape (Bs, [6, num_features])\n",
    "\ts = np. zeros ([129, num_features] )\n",
    "\th = np. zeros ([129, num_features])\n",
    "\tfor t in range (X. shape [0]) :\n",
    "\t\tz = sigmoid (np.matmul (Us [0, :, :], X[t, :]) +\n",
    "np.matmul (Ws [0, :, :], s[t, :]) + Bs[0, :] + Bs[3, :])\n",
    "\t\tr = sigmoid (np.matmul (Us [1, :, :], X[t, :]) +\n",
    "np.matmul (Ws [1, :, :], s[t, :]) + Bs[l, :] + Bs[4, :])\n",
    "\t\th[t+l, :] = np. tanh (np.matmul (Us [2, :, :], X[t, :]) +\n",
    "Bs[2, :] +\n",
    "r* (np.matmul (Ws [2, :, :], s[t, :]) + Bs[5, :]))\n",
    "\t\ts[t+l, :] = (1 - z)*h[t + 1, :] + z*s[t, :]\n",
    "\treturn h, s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oSHCkKTVPkb2",
   "metadata": {
    "id": "oSHCkKTVPkb2"
   },
   "source": [
    "Механизм GRU в настоящее время является одним из наиболее широко используемых решений RNN. Это простейшая версия архитектуры с долгой кратковременной памятью (LSTM — Long Short-Time Memory), которая работает аналогичным образом. Различия между ячейками GRU и LSTM заключаются в следующем.\n",
    "\n",
    "- У GRU есть два шлюза, а у LSTM — три. Эти шлюзы используются для определения объема разрешенной новой информации, сохраняемой старой информации и т.д. У LSTM больше шлюзов, а потому больше и параметров.\n",
    "\n",
    "- LSTM, как правило, обладает лучшей производительностью, но GRU быстрее обучается (из-за меньшего количества параметров). Тем не менее есть свидетельства, когда GRU превосходит LSTM по производительности. Скорее всего, GRU оказываются лучше LSTM при решении неязыковых задач.\n",
    "\n",
    "Как видите, разница в большей степени зависит от сложности соответствующей модели и производительности вычислительной системы, на которых выполняется обучение, а также от предмета прогнозирования. Важно разобраться в принципах матричной реализации механизмов GRU и LSTM, чтобы понимать, как они работают. Познакомившись с ними, вы научитесь определять, в каких ситуациях модели не обучаются на определенных наборах данных и почему. Зачастую в динамике проявляются неучтенные в рамках выбранного формата факторы.\n",
    "\n",
    "Обратите внимание, что как GRU, так и LSTM помогают решить проблему, которая впервые возникла при использовании RNN, а именно — взрывающиеся и исчезающие градиенты. Из-за повторяющегося применения одних и тех же параметров часто случалось, что градиенты быстро устремлялись к нулю (что плохо) или к бесконечности (что также плохо). Это означает, что обратное распространение было трудным или даже невозможным при развертывании рекуррентной сети. Эта проблема была успешно разрешена с помощью архитектур GRU и LSTM, поскольку они, как правило, поддерживают входы и выходы узлов в диапазонах допустимых значений. Это связано как с особой формой функции активации, которая в них используется, так и со способностью шлюза обновлений к передаче (или блокированию) проходящей через него информации, что позволяет градиенту с большей вероятностью принимать правдоподобные значения, чем это происходит в обычной RNN, лишенной шлюзов.\n",
    "\n",
    "Хотя GRU и LSTM достаточно легко написать самому, как показано выше, делать это совсем необязательно. Наиболее важная причина обратиться к готовым решениям заключается в их лучшей оптимизации за счет объединения операций матричного умножения. Наиболее эффективная и доступная сторонняя реализация, стоящая нашего внимания, представлена в библиотеке cuDNN, разработанной компанией NVIDIA, в которой операции умножения матриц выполняются одновременно, что крайне важно для GRU и LSTM. Использование программного интерфейса cuDNN позволило добиться существенного прироста производительности по сравнению с другими решениями, что было признано основным фактором повышения скорости обучения на конкурсе Kaggle. Все основные фреймворки глубокого обучения обеспечивают доступ к этой реализации, хотя в некоторых случаях (например, при работе с tf.contrib.cudnn_rnn в библиотеке TensorFlow) для ее подключения необходимо использовать специальный программный интерфейс. В других случаях, таких как MXNet, вы будете применять cuDNN по умолчанию, если не сделаете что-то необычное с развернутыми узлами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l2bRJVZJPl92",
   "metadata": {
    "id": "l2bRJVZJPl92"
   },
   "source": [
    "## Продолжение примера по прогнозированию объемов потребления электроэнергии\n",
    "Теперь давайте перейдем к решению задачи по прогнозированию потребления электроэнергии с помощью RNN. Как и ранее, входные данные будут представлены в формате TNC. Это вполне ожидаемый для RNN формат, и нам не придется его изменять.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "MVlzrDzsPnSj",
   "metadata": {
    "id": "MVlzrDzsPnSj"
   },
   "outputs": [],
   "source": [
    "def rnn_model(iter_train, input_feature_shape, X, Y,\n",
    "              win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "    rnn_cells.add(mx.rnn.GRUCell(num_hidden=RNN_UNITS))\n",
    "    rnn_cells.add(mx.rnn.DropoutCell(drop))\n",
    "    outputs, _ = rnn_cells.unroll(length=win, inputs=X, merge_outputs=False)\n",
    "    rnn_output = outputs[-1]\n",
    "\n",
    "    output = mx.sym.FullyConnected(data=rnn_output, num_hidden=input_feature_shape[2])\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BpChQ7XEPwoE",
   "metadata": {
    "id": "BpChQ7XEPwoE"
   },
   "source": [
    "Производительность модели разочаровывает, учитывая, что она исходно предназначена для обработки временных данных.\n",
    "Здесь важно разобраться, почему модель не демонстрирует хорошую производительность. Разве мы не предоставили достаточно параметров для RNN? Можно ли улучшить результат за счет добавления в модель некоторых архитектурных решений, которые обычно применяются в подобных случаях, например, учесть фактор внимания? (Относится как к RNN, так и к сетям прямого распространения, рассматриваемым ранее.)\n",
    "\n",
    "Модель достигла своих пиковых показателей в процессе обучения немного раньше, чем модели прямого распространения или сверточные модели. Это может быть вызвано как нехваткой параметров для описания набора данных, так и тем, что RNN специально приспособлена для обработки таких данных, или чем-то еще. Чтобы понять истинную причину, вам придется провести дополнительное тестирование с подбором настроек.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a1915-3c95-4c59-a317-5f5245d0b6d8",
   "metadata": {},
   "source": [
    "## Изобретение автокодировщиков\n",
    "\n",
    "Иногда вы можете столкнуться с набором данных, на котором даже очень простая модель показывает необычайно впечатляющие результаты (Ходят слухи, что в какой-то момент Google Translate работал на довольно простой семислойной сети LSTM. Однако не стоит недооценивать вклад громадных наборов данных и продуманного обучения. Не все простые модели одинаковы!). Но зачастую добиться хорошей скорости вычисления позволяет только нестандартный подход к решению задачи. Например, на ранних этапах исследования было обнаружено, что простое улучшение RNN может существенно повысить производительность в задачах моделирования последовательностей. Хотя изначально RNN разрабатывалась для изучения языков и машинного перевода, она часто показывала хорошие результаты при решении более сложных задач, таких как прогнозирование энергопотребления или предсказание цен на акции. Эта модель, известная как автокодировщик, или seq2seq, используется очень часто, и вам следует обязательно включить ее в набор инструментов глубокого обучения для временных рядов (рис. 9.12). Мы будем обращаться к ее помощи в примерах нескольких разделов, в которых рассматриваются задачи анализа реальных временных рядов.\n",
    "\n",
    "Автокодировщик состоит из двух рекуррентных слоев, но не в традиционном понимании, предполагающем последовательную обработку каждого входа. В автокодировщике первый слой работает до конца. Затем его скрытое состояние передается на второй слой, который принимает это скрытое состояние и собственные выходы в качестве новых входных данных для следующего шага. Эта модель была продиктована идеей машинного перевода, согласно которой вывод прогноза на каждом временном шаге не имеет смысла, поскольку в разных языках порядок слов и понятий может существенно различаться, но означать одно и то же. Предположение заключалась в том, что после обработки временного ряда первым слоем скрытое состояние могло представлять своего рода завершенную функциональность. Ее результат передавался в новую модель, которая постепенно раскрывала смысл нового языка, комбинируя результат с собственным выводом на каждом временном шаге.\n",
    "\n",
    "![data](picture10.png)\n",
    "\n",
    "*Рис. 9.12. Автокодировщик, также известный как модель seq2seq, — популярное средство обработки языковых структур и моделирования, которое также успешно применяется для анализа временных рядов*\n",
    "\n",
    "Как упоминалось ранее, несмотря на целевое предназначение, заключающееся в обработке языка, эта модель хорошо проявляет себя при решении традиционных задач, таких как прогнозирование одно- или многомерных временных рядов. Например, в конкурсе Kaggle по прогнозированию веб-трафика в сообщениях Википедии первое место после подбора многих гиперпараметров и архитектурных компонентов в конечном итоге заняла модель автокодировщика.\n",
    "Преимущество победителя, скорее всего, заключалось в продуманном обучении и поиске гиперпараметров, а также в правильной генерации и выборе полезных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dnqJRC_TPzAF",
   "metadata": {
    "id": "dnqJRC_TPzAF"
   },
   "source": [
    "## Комбинированные архитектуры\n",
    "Очень часто успешные промышленные и конкурсные приложения глубокого обучения, предназначенные для прогнозирования временных рядов, используют обновленную архитектуру, заключающуюся в новых способах применения традиционных механизмов LSTM или комбинировании некоторых других компонентов. Одним из примеров такого решения выступает нейронная сеть 2018 года, предложенная исследователями Университета Карнеги-Меллона. Разработчики стремились максимально задействовать сильные стороны как сверточных, так и рекуррентных архитектур, а также некоторых других инноваций. Они создали рекуррентную модель с пропуском слоя, которая настроена так, чтобы учитывать периодичность данных (годовую, еженедельную, ежедневную  в зависимости от характера набора данных), которую также можно задать с помощью гиперпараметра.\n",
    "\n",
    "Оказалось, что во многих временных рядах есть тренды, которые плохо моделируются нелинейными моделями глубокого обучения. Это означает, что одна только модель глубокого обучения не способна охватить существенные временные масштабы, наблюдаемые в некоторых временных рядах. Исследователи адаптировали архитектуру для решения подобных проблем с помощью традиционной линейной модели, а именно  модели авторегрессии, рассматриваемой в разделе 5.\n",
    "\n",
    "Итоговая модель, модифицированная LSTNet, комбинировала выходы модели AR и модели с традиционным рекуррентным слоем и параллельным пропуском рекуррентного слоя. Входы, подаваемые на каждый рекуррентный слой, служили выходами сверточных слоев, которые сворачивались как по оси времени, так и по оси канала (рис. 9.13).\n",
    "\n",
    "![data](picture11.png)\n",
    "\n",
    "*Рис. 9.13. В модифицированной LSTNet в архитектуру нейронной сети добавлен авторегрессионный компонент (внизу).*\n",
    "\n",
    "Архитектура нейронной сети содержит компонент свертки и рекуррентный элемент в последовательном порядке, причем оба компонента используют одни и те же входные данные.\n",
    "\n",
    "Обнаружено, что для трех из четырех исследуемых наборов данных, охватывающих широкий спектр тематических областей, были получены результаты, которые намного превзошли все опубликованные до этого. Неудача наблюдалась только в случае данных о курсах валют, которые, как известно, очень сложно предсказать из-за высокого соотношения “шум/сигнал” и существования высокоэффективного рынка, обеспечивающего быстрое рассеивание любого сигнала, что обусловлено стремлением инвесторов к нахождению граничного значения.\n",
    "\n",
    "Источником вдохновения для следующей разработки послужила научная статья. Мы будем работать с модифицированным кодом (https://perma.сс/3W4Y-E8E2) (Этот код можно найти в персональном репозитории Оливера Прингла (Oliver Pringle) на GitHub), заимствованным из каталога примеров для пакета MXNet, подробно описанного разработчиком Оливером Принглом в посте, опубликованном в его блоге (https://perma.cc/9KM2-RNPK).\n",
    "\n",
    "Здесь, как отмечалось ранее, применяется упрощенный код, подготовленный для репозитория MXNet, из которого удалены сезонные компоненты и пропуски соединений, а также используется сверточный фильтр только одного размера. Сверточный слой задается так же, как в примере cnn_model ранее.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "iAMrLXFSQEFC",
   "metadata": {
    "id": "iAMrLXFSQEFC"
   },
   "outputs": [],
   "source": [
    "# ЭТО ФРАГМЕНТ КОДА, А НЕ ПОЛНОЦЕННАЯ ЧАСТЬ ПРОГРАММЫ.\n",
    "\n",
    "# ## Для обработки данные должны быть четырех- или пятимерными\n",
    "# conv_input = mx.sym.reshape (data=X, shape=(0, 1, win, -1))\n",
    "\n",
    "# ## Сверточный компонент\n",
    "# ## Дополнение данных до конца временного окна\n",
    "# cnn_output = mx.sym.pad(data=conv_input,\n",
    "# mode= \"constant\",\n",
    "# constant_value=0,\n",
    "# pad_width=(0, 0,\n",
    "#         0, 0,\n",
    "#         0, sz_filt - 1,\n",
    "#         0, 0))\n",
    "# cnn_output = mx.sym.Convolution(data=cnn_output,\n",
    "# kernel=(sz_filt,\n",
    "# input_feature_shape[2]),\n",
    "# num_filter=n_filter)\n",
    "# cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "# cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output, axes= (0, 2, 1, 3)),shape=(0, 0, 0))\n",
    "# cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "# ## RNN применяется не к исходным данным, а к результатам работы сверточного компонента.\n",
    "\n",
    "# ## Рекуррентный компонент\n",
    "# stacked_rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "# stacked_rnn_cells.add(mx.rnn.GRUCell(num_hidden=args.rnn_units))\n",
    "# outputs, _ = stacked_rnn_cells.unroll(length=win,\n",
    "# \t\t\t\t\t\tinputs=cnn_output,\n",
    "# \t\t\t\t\t\tmerge_outputs=False)\n",
    "# rnn_output = outputs [-1]\n",
    "# n_outputs = input_feature_shape [2]\n",
    "# cnn_rnn_model = mx.sym.FullyConnected(data=rnn_outputz,\n",
    "# \t\t\t\t\t\tnum_hidden=n_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sdeWyXbQQGcO",
   "metadata": {
    "id": "sdeWyXbQQGcO"
   },
   "source": [
    "Наконец, как показано далее, параллельно с CNN/RNN обучаются AR-модели (всего - 321 AR-модель, по одной на столбец/переменную/электростанцию). Совершается проход по станциям так, что в отдельный момент времени в модели настраивается по одной станции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "BYTaq9iHQG2t",
   "metadata": {
    "id": "BYTaq9iHQG2t"
   },
   "outputs": [],
   "source": [
    "def simple_lstnet_model(iter_train,  input_feature_shape, X, Y,\n",
    "                        win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    ## must be 4d or 5d to use padding functionality\n",
    "    conv_input = mx.sym.reshape(data=X, shape=(0, 1, win, -1))\n",
    "\n",
    "    ## convolutional element\n",
    "    ## we add padding at the end of the time win\n",
    "    cnn_output = mx.sym.pad(data=conv_input,\n",
    "                            mode=\"constant\",\n",
    "                            constant_value=0,\n",
    "                            pad_width=(0, 0,\n",
    "                                       0, 0,\n",
    "                                       0, sz_filt - 1,\n",
    "                                       0, 0))\n",
    "    cnn_output = mx.sym.Convolution(data=cnn_output,\n",
    "                                    kernel=(sz_filt,\n",
    "                                            input_feature_shape[2]),\n",
    "                                    num_filter=n_filter)\n",
    "    cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "    cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output,\n",
    "                                                 axes=(0, 2, 1, 3)),\n",
    "                                shape=(0, 0, 0))\n",
    "    cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "\n",
    "    ## recurrent element\n",
    "    stacked_rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "    stacked_rnn_cells.add(mx.rnn.GRUCell(num_hidden=RNN_UNITS))\n",
    "    outputs, _ = stacked_rnn_cells.unroll(length=win,\n",
    "                                          inputs=cnn_output,\n",
    "                                          merge_outputs=False)\n",
    "    rnn_output = outputs[-1] # only take value from final unrolled cell for use later\n",
    "    n_outputs = input_feature_shape[2]\n",
    "    cnn_rnn_model = mx.sym.FullyConnected(data=rnn_output,\n",
    "                                          num_hidden=n_outputs)\n",
    "\n",
    "    ## ar element\n",
    "    ar_outputs = []\n",
    "    for i in list(range(input_feature_shape[2])):\n",
    "        ar_series = mx.sym.slice_axis(data=X,\n",
    "                                      axis=2,\n",
    "                                      begin=i,\n",
    "                                      end=i+1)\n",
    "        fc_ar = mx.sym.FullyConnected(data=ar_series, num_hidden=1)\n",
    "        ar_outputs.append(fc_ar)\n",
    "    ar_model = mx.sym.concat(*ar_outputs, dim=1)\n",
    "\n",
    "    output = cnn_rnn_model + ar_model\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HNbe4Y-8QVSw",
   "metadata": {
    "id": "HNbe4Y-8QVSw"
   },
   "source": [
    "Обратите внимание, что эта модель показывает намного лучшую производительность, чем любые другие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e50d8ef-e57e-4a5c-8b06-6c891b7e21d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Cor     Validation Cor\n",
      "0         0.032809       0.030814 \n",
      "1         0.078588       0.073627 \n",
      "2         0.126315       0.118714 \n",
      "3         0.175646       0.165735 \n",
      "4         0.226000       0.214213 \n",
      "5         0.276625       0.263352 \n",
      "6         0.326612       0.312158 \n",
      "7         0.375088       0.359670 \n",
      "8         0.421449       0.405118 \n",
      "9         0.465288       0.447881 \n",
      "10         0.506276       0.487498 \n",
      "11         0.544195       0.523798 \n",
      "12         0.578726       0.556571 \n",
      "13         0.609524       0.585608 \n",
      "14         0.636586       0.611066 \n",
      "15         0.660156       0.633312 \n",
      "16         0.680556       0.652712 \n",
      "17         0.698166       0.669592 \n",
      "18         0.713396       0.684263 \n",
      "19         0.726625       0.697029 \n",
      "20         0.738173       0.708201 \n",
      "21         0.748334       0.718092 \n",
      "22         0.757345       0.726940 \n",
      "23         0.765412       0.734939 \n",
      "24         0.772695       0.742235 \n",
      "25         0.779325       0.748933 \n",
      "26         0.785388       0.755102 \n",
      "27         0.790961       0.760797 \n",
      "28         0.796111       0.766066 \n",
      "29         0.800887       0.770951 \n",
      "\n",
      " TESTING PERFORMANCE\n",
      "{'COR': 0.77626044}\n"
     ]
    }
   ],
   "source": [
    "iter_train, iter_val, iter_test = prepare_iters(DATA_FILE, WIN, H, 'simple_lstnet_model', BATCH_N)\n",
    "input_feature_shape = iter_train.provide_data[0][1]\n",
    "X                   = mx.sym.Variable(iter_train.provide_data[0].name)\n",
    "Y                   = mx.sym.Variable(iter_train.provide_label[0].name)\n",
    "model = model_dict['simple_lstnet_model']\n",
    "symbol, data_names, label_names = model(iter_train,\n",
    "                                        input_feature_shape, X, Y,\n",
    "                                        WIN, SZ_FILT,\n",
    "                                        N_FILT, DROP, SEASONAL_PERIOD)\n",
    "train(symbol, iter_train, iter_val, iter_test, data_names, label_names, SAVE_DIR, GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff92ef-23a6-4645-ad5d-53f525672350",
   "metadata": {},
   "source": [
    "Очевидно, модель работает намного производительнее, чем другие рассматриваемые нами модели, а значит, в предложенной архитектуре есть что-то, что позволяет эффективно использовать сверточные изображения для представления последовательных данных, на которых обучается рекуррентный слой. Традиционный инструмент статистического анализа — AR-модель — также вносит немалый вклад в общее повышение производительности (Если сомневаетесь, то попробуйте провести обучение модели без AR-компонента. Его код удалить совершенно нетрудно). Эта модель, безусловно, лучшая из предложенных, и она оказывается в большом отрыве от остальных решений, по крайней мере для того небольшого объема данных, который подвергался анализу. Вы, конечно же, вправе использовать и другие модели, но вам не придется долго раздумывать, чтобы определить явного лидера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M7pOW7NfQXRb",
   "metadata": {
    "id": "M7pOW7NfQXRb"
   },
   "source": [
    "# Резюме\n",
    "Одно из интереснейших наблюдений, сделанных по результатам обучения, проводимого в этом разделе, заключается в том, что характеристики моделей оказались далеко не такими, как ожидалось. Простая сеть прямого распространения существенно превзошла некоторые другие модели, которые концептуально имеют более сложную организацию. Однако это ни в коей мере не значит, что одни модели лучше или хуже других для предложенного набора данных по целому ряду причин.\n",
    "\n",
    "- В каждой модели используется свое, отличное от других, количество параметров. Возможно, что разные типы моделей будут характеризоваться сильно различающейся производительностью для разного количества параметров. Также можно “поиграть” со сложностью модели, например, задавая разное количество сверточных/рекуррентных слоев или фильтров/скрытых элементов.\n",
    "\n",
    "- Гиперпараметры моделей не настраивались. Иногда правильное задание гиперпараметров оказывает наибольшее влияние на производительность модели.\n",
    "\n",
    "- Данные изучены недостаточно, чтобы получить хотя бы предварительное представление о том, какая модель лучше или хуже, учитывая временные корреляции и корреляции между различными столбцами/электростанциями.\n",
    "\n",
    "## Об улучшении навыков\n",
    "Просматривая публикации в научных журналах, материалах конференций и статьях на arXiv в поисках источников сведений о технологиях глубокого обучения для временных рядов, вы будет сильно разочарованы.\n",
    "\n",
    "• Многие исследователи временных рядов в первую очередь считают себя экспертами в предметной области и лишь во вторую — специалистами по анализу временных рядов. Это означает, что вам придется разбираться в смежных областях, таких как экономика, здравоохранение и исследование климатических изменений.\n",
    "\n",
    "• Специалисты по глубокому обучению часто считают глубокое обучение или нейронные сети технологиями, основанными на свертках. Поэтому, попытавшись разобраться в “рекуррентных нейронных сетях”, обязательно проводите поиск по указанным названиям. В большинстве работ, в названиях которых не встречается аббревиатура RNN (или схожая с ней), вы не найдете описания рекуррентных нейронных сетей.\n",
    "\n",
    "• К сожалению, еще никто не написал модель глубокого обучения, способную выполнить поиск документов по глубокому обучению, хотя это, несомненно, был бы достойный проект.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c1228-b029-41e7-bd21-bbb8596e8f19",
   "metadata": {},
   "source": [
    "## Дополнительные источники\n",
    "• Исторические документы\n",
    "Sepp Hochreiter and Jurgen Schmidhuber, “Long Short-Term Memory” Neural Computation 9, no. 8 (1997):1735-80, https://perma.cc/AHR3-FU5H\n",
    "\n",
    "В этой основополагающей работе 1997 года впервые описана архитектура с долгой кратковременной памятью (LSTM), а также предложено несколько экспериментальных тестов, которые до сих пор используются для обучения производительности нейронной сети при анализе последовательностей данных.\n",
    "\n",
    "Peter G. Zhang, Eddy Patuwo, and Michael Hu, “Forecasting with Artificial Neural Networks: The State of the Art,” International Journal of Forecasting 14, no. 1 (1998): 35-62, https: //perma. cc/Z32G-4ZQ3\n",
    "\n",
    "Здесь приведен обзор технологий анализа временных рядов и глубокого обучения на 1998 год.\n",
    "\n",
    "•\tСети RNN\n",
    "Aurelien Geron, “Processing Sequences Using RNNs and CNNs,\" in Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition (Sebastopol: O'Reilly Media, Inc., 2019).\n",
    "\n",
    "В этой популярной книге Орельен Жерон приводит очень много примеров применения глубокого обучения к данным временных рядов. Если вы чувствуете себя уверенно с такими инструментами, то обязательно воспользуйтесь виртуальным ноутбуком Jupyter (https://perma.cc/ D3UG-59SX) для просмотра наглядных примеров использования различных типов моделей для обработки последовательных данных, включая некоторые упражнения с готовыми решениями.\n",
    "\n",
    "Valentin Flunkert, David Salinas and Jan Gasthaus, “DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks,\" unpublished paper, 2017, https://perma.cc/MT7N-A2L6\n",
    "\n",
    "Содержит описание новаторской модели Amazon, которая была разработана с оглядкой на анализ временных рядов с данными о ее розничных продажах, которые представлены в самых разных временных масштабах и имеют различные тренды. Одним из нововведений модели была способность составлять вероятностные прогнозы, в отличие от общепринятых точечных оценок, которые, как правило, являются результатом анализа, проводимого с помощью технологий глубокого обучения.\n",
    "\n",
    "Lingxue Zhu and Nikolay Laptev, “Deep and Confident Prediction for Time Series at Uber\" paper presented at the 2017 IEEE International Conference on Data Mining Workshops (ICDMW), New Orleans, LA, https: / /perma. cc/PV8R-PHV4\n",
    "\n",
    "В статье описывается еще один пример применения вероятностных и статистических инструментов для модификации стандартной RNN. В данном случае компания Uber предложила новую глубокую байесовскую модель, которая проводила как точечную оценку, так и оценку неопределенности, которая разворачивалась в высокопроизводительную среду.\n",
    "\n",
    "Zhengping Che et al., “Recurrent Neural Networks for Multivariate Time Series with Missing Values,\" Scientific Reports 8, no. 6085 (2018), https: //perma. cc/4YM4-SFNX\n",
    "\n",
    "Яркий пример современного подхода к обработке медицинских временных рядов. В статье продемонстрирован пример совместного использования GRU и новаторских архитектур для учета отсутствующих данных и превращения отсутствующих данных в информативный признак. Авторы описывают нейронные сети, способные учитывать все клинические показатели, используемые в настоящее время, для прогнозирования состояния здоровья пациентов, которые пребывают на стационарном лечении.\n",
    "\n",
    "Прекрасный пример того, как интуитивное и простое для понимания изменение простой и широко используемой архитектуры RNN (GRU) может привести к отличным результатам на хорошем наборе данных.\n",
    "\n",
    "• Сети CNN\n",
    "Aaron van den Oord and Sander Dieleman, “WaveNet: A Generative Model for Raw Audio DeepMind,” DeepMind blog, September 8, 2016, https: / /perma. cc/G37Y-WFCM\n",
    "\n",
    "Блог, содержащий чрезвычайно подробное и простое для понимания описание улучшенной архитектуры CNN, используемой для совершенствования технологий преобразования текста в речь, а речи — в текст для разных языков и носителей. Обновленная архитектура характеризуется повышенной производительностью и была развернута для решения других задач искусственного интеллекта, связанных с обработкой последовательностей данных, в первую очередь прогнозирования временных рядов.\n",
    "\n",
    "• Глубокое обучение\n",
    "Vera Rimmer et al., Automated Website Fingerprinting Through Deep Learning,”paper presented at NDSS 2018, San Diego, CA, https: //perma. cc/YR2G-UJUW\n",
    "\n",
    "В этом документе рассматривается способ использования алгоритмов глубокого обучения для получения данных о поведении пользователей в Интернете через снятие “отпечатков пальцев” с веб-сайтов. В частности, авторы выделили способ, который различные архитектуры нейронных сетей могут использовать для преодоления взлома систем защиты конфиденциальных данных пользователей, основанной на использовании отпечатков веб-сайтов.\n",
    "\n",
    "СРМР, “Second Place Solution to the Kaggle Web Traffic Forecasting Competition,”Kaggle blog, 2017, https://perma.cc/UUR4-VNEU\n",
    "\n",
    "Этот пост, написанный еще до завершения конкурса, содержит размышления второго призера о разработке решения для прогнозирования, основанного на смешанной архитектуре машинного/глубокого обучения. В сообщении, опубликованном в блоге (https: / /perma. сс/73M3-D7DW), приведен также ретроспективный комментарий. Здесь рассматривается отличный пример совместного использования современных пакетов и соответствующего стиля программирования. Описание решения, занявшего первое место, вместе с обсуждением его архитектуры на основе нейронной сети (https: / /perma. cc/G9DW-T8LE) можно найти в репозитории GitHub (https: / /perma. cc/K6RW-KA9E).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
